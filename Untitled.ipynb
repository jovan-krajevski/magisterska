{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fae0e69-66a8-40a3-a99f-a98bd87baf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import pytensor as pyt\n",
    "from random import randint\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "\n",
    "logging.getLogger(\"prophet\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"cmdstanpy\").disabled=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e849b781-323a-47dd-bb96-3aed720fd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NANOSECONDS_TO_SECONDS = 1000 * 1000 * 1000\n",
    "\n",
    "class MyProphet():\n",
    "    def __init__(self,\n",
    "                 n_changepoints=25,\n",
    "                 changepoints_prior_scale=0.05,\n",
    "                 changepoint_range=0.8,\n",
    "                 seasonality_prior_scale=10.0,\n",
    "                 mcmc_samples=0,\n",
    "                 k_mean=0,\n",
    "                 k_sd=5,\n",
    "                 m_mean=0,\n",
    "                 m_sd=5,\n",
    "                 sigma=0.5,\n",
    "                 delta_mean=0,\n",
    "                 beta_yearly_mean=0,\n",
    "                 beta_weekly_mean=0,\n",
    "                ):\n",
    "        self.n_changepoints = n_changepoints\n",
    "        self.changepoints_prior_scale = changepoints_prior_scale\n",
    "        self.changepoint_range = changepoint_range\n",
    "        self.seasonality_prior_scale = seasonality_prior_scale\n",
    "        self.mcmc_samples = mcmc_samples\n",
    "        \n",
    "        self.k_mean = k_mean\n",
    "        self.k_sd = k_sd\n",
    "        self.m_mean = m_mean\n",
    "        self.m_sd = m_sd\n",
    "        self.sigma = sigma\n",
    "        self.delta_mean = delta_mean\n",
    "        self.beta_yearly_mean = beta_yearly_mean\n",
    "        self.beta_weekly_mean = beta_weekly_mean\n",
    "        \n",
    "        self.model = None\n",
    "        self.init_vals = None\n",
    "        self.trend_params = None\n",
    "        self.yearly_seasonality_params = None\n",
    "        self.weekly_seasonality_params = None\n",
    "        self.map_approx = None\n",
    "        self.trace = None\n",
    "        self.posterior = None\n",
    "        \n",
    "        self.data = None\n",
    "        self.y_min = None\n",
    "        self.y_max = None\n",
    "        self.ds_min = None\n",
    "        self.ds_max = None\n",
    "\n",
    "    def _scale_data(self):\n",
    "        self.y_min = 0\n",
    "        self.y_max = self.data[\"y\"].abs().max()\n",
    "        self.ds_min = self.data[\"ds\"].min()\n",
    "        self.ds_max = self.data[\"ds\"].max()\n",
    "\n",
    "        self.data[\"y\"] = self.data[\"y\"] / self.y_max\n",
    "        self.data[\"t\"] = (self.data[\"ds\"] - self.ds_min) / (self.ds_max - self.ds_min)\n",
    "        \n",
    "    def _process_data(self):\n",
    "        self.data[\"ds\"] = pd.to_datetime(self.data[\"ds\"])\n",
    "        self.data.sort_values(\"ds\", inplace=True)\n",
    "        self._scale_data()\n",
    "\n",
    "    def _model_init(self):\n",
    "        i0, i1 = self.data[\"ds\"].idxmin(), self.data[\"ds\"].idxmax()\n",
    "        T = self.data[\"t\"].iloc[i1] - self.data[\"t\"].iloc[i0]\n",
    "        k = (self.data[\"y\"].iloc[i1] - self.data[\"y\"].iloc[i0]) / T\n",
    "        m = self.data[\"y\"].iloc[i0] - k * self.data[\"t\"].iloc[i0]\n",
    "        delta = np.zeros(self.n_changepoints)\n",
    "        self.init_vals = {\"k\": k, \"m\": m, \"delta\": delta, \"beta_yearly\": 0.0, \"beta_weekly\": 0.0, \"sigma\": 1.0}\n",
    "\n",
    "    def _add_trend(self):\n",
    "        t = np.array(self.data[\"t\"])\n",
    "        hist_size = int(np.floor(self.data.shape[0] * self.changepoint_range))\n",
    "        cp_indexes = np.linspace(0, hist_size - 1, self.n_changepoints + 1).round().astype(int)\n",
    "        s = np.array(self.data.iloc[cp_indexes][\"t\"].tail(-1))\n",
    "    \n",
    "        # * 1 casts the boolean to integers\n",
    "        A = (t[:, None] > s) * 1\n",
    "    \n",
    "        with self.model:\n",
    "            # initial growth\n",
    "            k = pm.Normal(\"k\", self.k_mean , self.k_sd, initval=self.init_vals[\"k\"])\n",
    "\n",
    "            changepoints_prior_scale = self.changepoints_prior_scale\n",
    "            if self.changepoints_prior_scale is None:\n",
    "                changepoints_prior_scale = pm.Exponential(\"tau\", 1.5)\n",
    "        \n",
    "            # rate of change\n",
    "            delta = pm.Laplace(\"delta\", self.delta_mean, changepoints_prior_scale, shape=self.n_changepoints, initval=self.init_vals[\"delta\"])\n",
    "            # offset\n",
    "            m = pm.Normal(\"m\", self.m_mean, self.m_sd, initval=self.init_vals[\"m\"])\n",
    "            gamma = -s * delta\n",
    "            trend = pm.Deterministic(\"trend\", (k + pyt.tensor.dot(A, delta)) * t + (m + pyt.tensor.dot(A, gamma)))\n",
    "\n",
    "        return trend, A, s\n",
    "\n",
    "    def _fourier_series(self, data, period=365.25, series_order=10,):\n",
    "        # convert to days since epoch\n",
    "        t = data[\"ds\"].to_numpy(dtype=np.int64) // NANOSECONDS_TO_SECONDS / (3600 * 24.)\n",
    "    \n",
    "        x_T = t * np.pi * 2\n",
    "        fourier_components = np.empty((data[\"ds\"].shape[0], 2 * series_order))\n",
    "        for i in range(series_order):\n",
    "            c = x_T * (i + 1) / period\n",
    "            fourier_components[:, 2 * i] = np.sin(c)\n",
    "            fourier_components[:, (2 * i) + 1] = np.cos(c)\n",
    "            \n",
    "        return fourier_components\n",
    "\n",
    "    def _get_seasonality_n_x(self, data, period):\n",
    "        if period == \"yearly\":\n",
    "            n = 10\n",
    "            p = 365.25\n",
    "        else:  # weekly\n",
    "            n = 3\n",
    "            p = 7\n",
    "            \n",
    "        return n, self._fourier_series(data, p, n)\n",
    "\n",
    "    def _add_seasonality(self, period, mean):\n",
    "        n, x = self._get_seasonality_n_x(self.data, period)\n",
    "    \n",
    "        with self.model:\n",
    "            beta = pm.Normal(f\"beta_{period}\", mu=mean, sigma=self.seasonality_prior_scale, shape=2 * n, initval=np.zeros(2 * n))\n",
    "            \n",
    "        return x, beta\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self._process_data()\n",
    "        self._model_init()\n",
    "\n",
    "        self.model = pm.Model()\n",
    "        with self.model:\n",
    "            trend, A, s = self._add_trend()\n",
    "            x_yearly, beta_yearly = self._add_seasonality(\"yearly\", self.beta_yearly_mean)\n",
    "            x_weekly, beta_weekly = self._add_seasonality(\"weekly\", self.beta_weekly_mean)\n",
    "            trend += pyt.tensor.dot(x_yearly, beta_yearly) + pyt.tensor.dot(x_weekly, beta_weekly)\n",
    "            # sigma = pm.HalfCauchy(\"sigma\", 0.5, initval=1)\n",
    "            sigma = pm.HalfNormal(\"sigma\", self.sigma, initval=self.init_vals[\"sigma\"])\n",
    "            obs = pm.Normal(\"obs\", mu=trend, sigma=sigma, observed=self.data[\"y\"])\n",
    "            \n",
    "            if self.mcmc_samples == 0:\n",
    "                t_0 = timeit.default_timer()\n",
    "                # call function\n",
    "                self.map_approx = pm.find_MAP(progressbar=False, maxeval=1e4)\n",
    "                # record end time\n",
    "                t_1 = timeit.default_timer()\n",
    "                 \n",
    "                # calculate elapsed time and print\n",
    "                elapsed_time = round(t_1 - t_0, 3)\n",
    "                # print(f\"Elapsed time: {elapsed_time} s\")\n",
    "                \n",
    "            else:\n",
    "                self.trace = pm.sample(self.mcmc_samples, return_inferencedata=True, chains=4)\n",
    "                # self.posterior = pm.sample_posterior_predictive(trace=self.trace)\n",
    "\n",
    "        self.trend_params = (trend, A, s)\n",
    "        self.yearly_seasonality_params = (x_yearly, beta_yearly)\n",
    "        self.weekly_seasonality_params = (x_weekly, beta_weekly)\n",
    "\n",
    "    def _det_seasonality_posterior(self, beta, x):\n",
    "        return np.dot(x, beta.T)\n",
    "\n",
    "    def _plot_predictions(self, future, y_true=None):\n",
    "        date = future[\"ds\"].dt.to_pydatetime()\n",
    "        plt.figure(figsize=(16, 3*6))\n",
    "        b = 411\n",
    "        plt.subplot(b)\n",
    "        plt.title(\"Predictions\")\n",
    "        plt.plot(date, future[\"yhat\"], lw=0.5)\n",
    "        plt.scatter(date[:len(self.data)], self.data[\"y\"] * self.y_max, s=0.5, color=\"black\")\n",
    "\n",
    "        if y_true is not None:\n",
    "            plt.scatter(date[len(self.data):], y_true, s=0.5, color=\"green\")\n",
    "\n",
    "        plt.subplot(b + 1)\n",
    "        plt.title(\"Trend\")\n",
    "        plt.plot(date, future[\"trend\"], lw=0.5)\n",
    "        # plt.scatter(date[:len(self.data)], self.data[\"y\"] * self.y_max, s=0.5, color=\"black\")\n",
    "\n",
    "    def _make_future_df(self, days):\n",
    "        future = pd.DataFrame({\n",
    "            \"ds\": pd.DatetimeIndex(pd.concat((\n",
    "                self.data[\"ds\"], \n",
    "                pd.date_range(self.ds_max, self.ds_max + pd.Timedelta(days, \"D\"), inclusive=\"right\").to_series(),\n",
    "            )))\n",
    "        })\n",
    "        future[\"t\"] = (future[\"ds\"] - self.ds_min) / (self.ds_max - self.ds_min)\n",
    "        return future\n",
    "    \n",
    "    def _predict_map(self, days, y_true=None, plot=False):\n",
    "        _, _, s = self.trend_params\n",
    "        future = self._make_future_df(days)\n",
    "        new_A = (np.array(future[\"t\"])[:, None] > s) * 1\n",
    "        \n",
    "        _, x_yearly = self._get_seasonality_n_x(future, \"yearly\")\n",
    "        _, x_weekly = self._get_seasonality_n_x(future, \"weekly\")\n",
    "        \n",
    "        future[\"yearly\"] = self._det_seasonality_posterior(self.map_approx[\"beta_yearly\"], x_yearly) * self.y_max\n",
    "        future[\"weekly\"] = self._det_seasonality_posterior(self.map_approx[\"beta_weekly\"], x_weekly) * self.y_max        \n",
    "        future[\"trend\"] = np.array((\n",
    "            (self.map_approx[\"k\"] + np.dot(new_A, self.map_approx[\"delta\"])) * future[\"t\"] + \n",
    "            (self.map_approx[\"m\"] + np.dot(new_A, (-s * self.map_approx[\"delta\"])))\n",
    "        ) * self.y_max)\n",
    "\n",
    "        future[\"yhat\"] = future[\"trend\"] + future[\"yearly\"] + future[\"weekly\"]\n",
    "\n",
    "        if plot:\n",
    "            self._plot_predictions(future, y_true)\n",
    "            \n",
    "        return future\n",
    "\n",
    "    def _predict_mcmc(self, days, y_true=None, plot=False):\n",
    "        _, _, s = self.trend_params\n",
    "        future = self._make_future_df(days)\n",
    "        new_A = (np.array(future[\"t\"])[:, None] > s) * 1\n",
    "\n",
    "        _, x_yearly = self._get_seasonality_n_x(future, \"yearly\")\n",
    "        _, x_weekly = self._get_seasonality_n_x(future, \"weekly\")\n",
    "        \n",
    "        beta_yearly = self.trace[\"posterior\"][\"beta_yearly\"].to_numpy().mean(0)\n",
    "        beta_weekly = self.trace[\"posterior\"][\"beta_weekly\"].to_numpy().mean(0)\n",
    "        delta = self.trace[\"posterior\"][\"delta\"].mean([\"chain\", \"draw\"])\n",
    "        k = self.trace[\"posterior\"][\"k\"].mean().to_numpy()\n",
    "        m = self.trace[\"posterior\"][\"m\"].mean().to_numpy()\n",
    "        \n",
    "        trend_forecast = []\n",
    "        \n",
    "        yearly_posterior = self._det_seasonality_posterior(beta_yearly, x_yearly) * self.y_max\n",
    "        weekly_posterior = self._det_seasonality_posterior(beta_weekly, x_weekly) * self.y_max\n",
    "\n",
    "        # TODO: fix this, loop makes no sense\n",
    "        for n in range(self.mcmc_samples):\n",
    "            trend_forecast.append(((k + np.dot(new_A, delta)) * future[\"t\"]  + (m + np.dot(new_A, (-s * delta)))) * self.y_max)   \n",
    "            \n",
    "        trend_forecast = np.array(trend_forecast)\n",
    "        \n",
    "        future[\"yhat\"] = (trend_forecast + yearly_posterior.T + weekly_posterior.T).mean(0)\n",
    "        future[\"trend\"] = trend_forecast.mean(0)\n",
    "        future[\"yearly\"] = yearly_posterior.T.mean(0)\n",
    "        future[\"weekly\"] = weekly_posterior.T.mean(0)\n",
    "\n",
    "        if plot:\n",
    "            self._plot_predictions(future, y_true)\n",
    "        \n",
    "        return future\n",
    "\n",
    "class MyProphetWrapper():\n",
    "    def __init__(self,\n",
    "                 n_changepoints=25,\n",
    "                 changepoints_prior_scale=0.05,\n",
    "                 changepoint_range=0.8,\n",
    "                 seasonality_prior_scale=10.0,\n",
    "                 mcmc_samples=0,\n",
    "                 k_mean=0,\n",
    "                 k_sd=5,\n",
    "                 m_mean=0,\n",
    "                 m_sd=5,\n",
    "                 sigma=0.5,\n",
    "                 delta_mean=0,\n",
    "                 beta_yearly_mean=0,\n",
    "                 beta_weekly_mean=0,\n",
    "                ):\n",
    "        self.n_changepoints = n_changepoints\n",
    "        self.changepoints_prior_scale = changepoints_prior_scale\n",
    "        self.changepoint_range = changepoint_range\n",
    "        self.seasonality_prior_scale = seasonality_prior_scale\n",
    "        self.mcmc_samples = mcmc_samples\n",
    "        \n",
    "        self.k_mean = k_mean\n",
    "        self.k_sd = k_sd\n",
    "        self.m_mean = m_mean\n",
    "        self.m_sd = m_sd\n",
    "        self.sigma = sigma\n",
    "        self.delta_mean = delta_mean\n",
    "        self.beta_yearly_mean = beta_yearly_mean\n",
    "        self.beta_weekly_mean = beta_weekly_mean\n",
    "\n",
    "    def _calculate_metrics(self, ys, yhats, horizon):\n",
    "        metrics = {\"horizon\": [], \"mse\": [], \"rmse\": [], \"mae\": [], \"mape\": []}\n",
    "\n",
    "        for k in tqdm(range(horizon)):\n",
    "            y_true = [y[y[\"day_idx\"] == k][\"y\"].values[0] for y in ys if k in y[\"day_idx\"].values]\n",
    "            y_pred = [y[y[\"day_idx\"] == k][\"y\"].values[0] for y in yhats if k in y[\"day_idx\"].values]\n",
    "            \n",
    "            metrics[\"horizon\"].append(k + 1)\n",
    "            metrics[\"mse\"].append(mean_squared_error(y_true, y_pred))\n",
    "            metrics[\"rmse\"].append(root_mean_squared_error(y_true, y_pred))\n",
    "            metrics[\"mae\"].append(mean_absolute_error(y_true, y_pred))\n",
    "            metrics[\"mape\"].append(mean_absolute_percentage_error(y_true, y_pred))\n",
    "\n",
    "        return pd.DataFrame.from_dict(metrics)\n",
    "\n",
    "    def test_prophet(self, df, window=730, horizon=365, extend_window=False, limit=None):\n",
    "        yhats = []\n",
    "        ys = []\n",
    "\n",
    "        l = len(df) - window - horizon - 1\n",
    "        if limit is not None:\n",
    "            l = limit\n",
    "        \n",
    "        for start in tqdm(range(l)):\n",
    "            model = Prophet(\n",
    "                n_changepoints=self.n_changepoints,\n",
    "                changepoint_prior_scale=self.changepoints_prior_scale,\n",
    "                changepoint_range=self.changepoint_range,\n",
    "                seasonality_prior_scale=self.seasonality_prior_scale,\n",
    "            )\n",
    "\n",
    "            if extend_window:\n",
    "                model.fit(df[:start + window])\n",
    "            else:\n",
    "                model.fit(df[start:start + window])\n",
    "\n",
    "            future = model.make_future_dataframe(periods=horizon, include_history=False)\n",
    "            \n",
    "            y = df[start + window:start + window + horizon].copy()\n",
    "            y[\"ds\"] = pd.to_datetime(y[\"ds\"])\n",
    "            yhat = model.predict(future)\n",
    "        \n",
    "            y = y[y[\"ds\"].isin(yhat[\"ds\"])]\n",
    "            yhat = yhat[yhat[\"ds\"].isin(y[\"ds\"])]\n",
    "        \n",
    "            y[\"day_idx\"] = (y[\"ds\"] - y[\"ds\"].min()).dt.days\n",
    "            ys.append(y)\n",
    "        \n",
    "            yhat[\"day_idx\"] = (yhat[\"ds\"] - yhat[\"ds\"].min()).dt.days\n",
    "            yhat[\"y\"] = yhat[\"yhat\"]\n",
    "            yhat.drop(yhat.columns.difference([\"ds\", \"y\", \"day_idx\"]), axis=1, inplace=True)\n",
    "            yhats.append(yhat)\n",
    "        \n",
    "\n",
    "        return self._calculate_metrics(ys, yhats, horizon)\n",
    "\n",
    "    def test_my_prophet(self, df, update_priors_days=1, window=730, horizon=365, extend_window=False, limit=None):\n",
    "        yhats = []\n",
    "        ys = []\n",
    "        \n",
    "        k_mean = self.k_mean\n",
    "        k_sd = self.k_sd\n",
    "        m_mean = self.m_mean\n",
    "        m_sd = self.m_sd\n",
    "        sigma = self.sigma\n",
    "        delta_mean = self.delta_mean\n",
    "        beta_yearly_mean = self.beta_yearly_mean\n",
    "        beta_weekly_mean = self.beta_weekly_mean\n",
    "\n",
    "        l = len(df) - window - horizon - 1\n",
    "        if limit is not None:\n",
    "            l = limit\n",
    "        \n",
    "        for start in tqdm(range(l)):\n",
    "            if update_priors_days > 0 and start % update_priors_days == 0:\n",
    "                mcmc_samples = self.mcmc_samples\n",
    "            else:\n",
    "                mcmc_samples = 0\n",
    "        \n",
    "            model = MyProphet(\n",
    "                n_changepoints=self.n_changepoints,\n",
    "                changepoints_prior_scale=self.changepoints_prior_scale,\n",
    "                changepoint_range=self.changepoint_range,\n",
    "                seasonality_prior_scale=self.seasonality_prior_scale,\n",
    "                mcmc_samples=mcmc_samples,\n",
    "                k_mean=k_mean,\n",
    "                k_sd=k_sd,\n",
    "                m_mean=m_mean,\n",
    "                m_sd=m_sd,\n",
    "                sigma=sigma,\n",
    "                delta_mean=delta_mean,\n",
    "                beta_yearly_mean=beta_yearly_mean,\n",
    "                beta_weekly_mean=beta_weekly_mean,\n",
    "            )\n",
    "\n",
    "            if extend_window:\n",
    "                model.fit(df[:start + window])\n",
    "            else:\n",
    "                model.fit(df[start:start + window])\n",
    "            \n",
    "            y = df[start + window:start + window + horizon].copy()\n",
    "            y[\"ds\"] = pd.to_datetime(y[\"ds\"])\n",
    "            yhat = model._predict_map(horizon) if mcmc_samples == 0 else model._predict_mcmc(horizon)\n",
    "        \n",
    "            y = y[y[\"ds\"].isin(yhat[\"ds\"])]\n",
    "            yhat = yhat[yhat[\"ds\"].isin(y[\"ds\"])]\n",
    "        \n",
    "            y[\"day_idx\"] = (y[\"ds\"] - y[\"ds\"].min()).dt.days\n",
    "            ys.append(y)\n",
    "        \n",
    "            yhat[\"day_idx\"] = (yhat[\"ds\"] - yhat[\"ds\"].min()).dt.days\n",
    "            yhat[\"y\"] = yhat[\"yhat\"]\n",
    "            yhat.drop(yhat.columns.difference([\"ds\", \"y\", \"day_idx\"]), axis=1, inplace=True)\n",
    "            yhats.append(yhat)\n",
    "        \n",
    "            if update_priors_days > 0 and start % update_priors_days == 0:\n",
    "                if self.mcmc_samples == 0:\n",
    "                    k_mean = model.map_approx[\"k\"]\n",
    "                    # k_sd = summary[\"sd\"][\"k\"]\n",
    "                    m_mean = model.map_approx[\"m\"]\n",
    "                    # m_sd = summary[\"sd\"][\"m\"]\n",
    "                    sigma = model.map_approx[\"sigma\"]\n",
    "                    delta = model.map_approx[\"delta\"]\n",
    "                    beta_yearly_mean = model.map_approx[\"beta_yearly\"]\n",
    "                    beta_weekly_mean = model.map_approx[\"beta_weekly\"]\n",
    "                else:\n",
    "                    summary = az.summary(model.trace, var_names=[\"k\", \"m\", \"sigma\"])\n",
    "                    \n",
    "                    k_mean = summary[\"mean\"][\"k\"]\n",
    "                    # k_sd = summary[\"sd\"][\"k\"]\n",
    "                    m_mean = summary[\"mean\"][\"m\"]\n",
    "                    # m_sd = summary[\"sd\"][\"m\"]\n",
    "                    # sigma = summary[\"sd\"][\"sigma\"]\n",
    "                \n",
    "                # print(k_mean, k_sd, m_mean, m_sd, sigma)\n",
    "\n",
    "        return self._calculate_metrics(ys, yhats, horizon)\n",
    "\n",
    "    def test_my_prophet_iter(self, df, horizon=365, extend_window=False, iters=10):\n",
    "        yhats = []\n",
    "        ys = []\n",
    "        metrics = []\n",
    "        \n",
    "        k_mean = self.k_mean\n",
    "        k_sd = self.k_sd\n",
    "        m_mean = self.m_mean\n",
    "        m_sd = self.m_sd\n",
    "        sigma = self.sigma\n",
    "        delta_mean = self.delta_mean\n",
    "        beta_yearly_mean = self.beta_yearly_mean\n",
    "        beta_weekly_mean = self.beta_weekly_mean\n",
    "\n",
    "        mcmc_samples = 0\n",
    "        l = len(df)\n",
    "        for k in tqdm(range(iters)):\n",
    "            model = MyProphet(\n",
    "                n_changepoints=self.n_changepoints,\n",
    "                changepoints_prior_scale=self.changepoints_prior_scale,\n",
    "                changepoint_range=self.changepoint_range,\n",
    "                seasonality_prior_scale=self.seasonality_prior_scale,\n",
    "                mcmc_samples=mcmc_samples,\n",
    "                k_mean=k_mean,\n",
    "                k_sd=k_sd,\n",
    "                m_mean=m_mean,\n",
    "                m_sd=m_sd,\n",
    "                sigma=sigma,\n",
    "                delta_mean=delta_mean,\n",
    "                beta_yearly_mean=beta_yearly_mean,\n",
    "                beta_weekly_mean=beta_weekly_mean,\n",
    "            )\n",
    "    \n",
    "\n",
    "            model.fit(df[:-horizon])\n",
    "            \n",
    "            y = df[-horizon:].copy()\n",
    "            y[\"ds\"] = pd.to_datetime(y[\"ds\"])\n",
    "            yhat = model._predict_map(horizon)\n",
    "        \n",
    "            y = y[y[\"ds\"].isin(yhat[\"ds\"])]\n",
    "            yhat = yhat[yhat[\"ds\"].isin(y[\"ds\"])]\n",
    "        \n",
    "            y[\"day_idx\"] = (y[\"ds\"] - y[\"ds\"].min()).dt.days\n",
    "            ys.append(y)\n",
    "        \n",
    "            yhat[\"day_idx\"] = (yhat[\"ds\"] - yhat[\"ds\"].min()).dt.days\n",
    "            yhat[\"y\"] = yhat[\"yhat\"]\n",
    "            yhat.drop(yhat.columns.difference([\"ds\", \"y\", \"day_idx\"]), axis=1, inplace=True)\n",
    "            yhats.append(yhat)\n",
    "            \n",
    "            k_mean = model.map_approx[\"k\"]\n",
    "            m_mean = model.map_approx[\"m\"]\n",
    "            sigma = model.map_approx[\"sigma\"]\n",
    "            delta = model.map_approx[\"delta\"]\n",
    "            beta_yearly_mean = model.map_approx[\"beta_yearly\"]\n",
    "            beta_weekly_mean = model.map_approx[\"beta_weekly\"]\n",
    "    \n",
    "            print(mean_absolute_percentage_error(y[\"y\"], yhat[\"y\"]))\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b97dec91-87f2-4c97-8a55-380e080e5103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-12-10</td>\n",
       "      <td>9.590761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-11</td>\n",
       "      <td>8.519590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-12</td>\n",
       "      <td>8.183677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-12-13</td>\n",
       "      <td>8.072467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-12-14</td>\n",
       "      <td>7.893572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>7.817223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>9.273878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>10.333775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>9.125871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>8.891374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2905 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ds          y\n",
       "0     2007-12-10   9.590761\n",
       "1     2007-12-11   8.519590\n",
       "2     2007-12-12   8.183677\n",
       "3     2007-12-13   8.072467\n",
       "4     2007-12-14   7.893572\n",
       "...          ...        ...\n",
       "2900  2016-01-16   7.817223\n",
       "2901  2016-01-17   9.273878\n",
       "2902  2016-01-18  10.333775\n",
       "2903  2016-01-19   9.125871\n",
       "2904  2016-01-20   8.891374\n",
       "\n",
       "[2905 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/facebook/prophet/main/examples/example_wp_log_peyton_manning.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95fac4a8-fd94-447a-ad6a-a9a14829f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████████████▎                                                                                                                                                           | 1/10 [00:01<00:14,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054115122346166986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████████▌                                                                                                                                          | 2/10 [00:17<01:21, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05392069132921085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████████▉                                                                                                                         | 3/10 [00:48<02:17, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054245423908719205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████████████████████████████████████▏                                                                                                       | 4/10 [01:03<01:46, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05282192489520781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                      | 5/10 [01:22<01:31, 18.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05508490702392869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 6/10 [01:53<01:30, 22.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05237289227648674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 7/10 [02:23<01:14, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054314883920286425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 8/10 [02:40<00:44, 22.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05281093607615366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 9/10 [02:56<00:20, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053290171932416495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:22<00:00, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0559193352676016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_wrapper = MyProphetWrapper()\n",
    "preds = model_wrapper.test_my_prophet_iter(df, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68661563-39cd-4764-8e6a-e062e7b6a2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053892839786617214"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon=365\n",
    "model = Prophet()\n",
    "model.fit(df[:-horizon])\n",
    "future = model.make_future_dataframe(periods=horizon, include_history=False)\n",
    "\n",
    "y = df[-horizon:].copy()\n",
    "y[\"ds\"] = pd.to_datetime(y[\"ds\"])\n",
    "yhat = model.predict(future)\n",
    "\n",
    "y = y[y[\"ds\"].isin(yhat[\"ds\"])]\n",
    "yhat = yhat[yhat[\"ds\"].isin(y[\"ds\"])]\n",
    "\n",
    "y[\"day_idx\"] = (y[\"ds\"] - y[\"ds\"].min()).dt.days\n",
    "\n",
    "yhat[\"day_idx\"] = (yhat[\"ds\"] - yhat[\"ds\"].min()).dt.days\n",
    "yhat[\"y\"] = yhat[\"yhat\"]\n",
    "yhat.drop(yhat.columns.difference([\"ds\", \"y\", \"day_idx\"]), axis=1, inplace=True)\n",
    "\n",
    "mean_absolute_percentage_error(y[\"y\"], yhat[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce58ca-6e91-4f2f-8792-6169284dfd88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
