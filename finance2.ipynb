{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "import yfinance\n",
    "\n",
    "logging.getLogger(\"prophet\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"cmdstanpy\").disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_definition(X, pool_cols, pool_type):\n",
    "    if pool_type == \"complete\":\n",
    "        group = np.zeros(len(X), dtype=\"int\")\n",
    "        group_mapping = {0: \"all\"}\n",
    "        n_groups = 1\n",
    "    else:\n",
    "        X[pool_cols] = pd.Categorical(X[pool_cols])\n",
    "        group = X[pool_cols].cat.codes.values\n",
    "        group_mapping = dict(enumerate(X[pool_cols].cat.categories))\n",
    "        n_groups = X[pool_cols].nunique()\n",
    "    return group, n_groups, group_mapping\n",
    "\n",
    "\n",
    "class TimeSeriesModel:\n",
    "    def _scale_data(self):\n",
    "        self.y_min = 0\n",
    "        self.y_max = self.data[\"y\"].abs().max()\n",
    "        self.ds_min = self.data[\"ds\"].min()\n",
    "        self.ds_max = self.data[\"ds\"].max()\n",
    "\n",
    "        self.data[\"y\"] = self.data[\"y\"] / self.y_max\n",
    "        self.data[\"t\"] = (self.data[\"ds\"] - self.ds_min) / (self.ds_max - self.ds_min)\n",
    "\n",
    "    def _process_data(self):\n",
    "        self.data[\"ds\"] = pd.to_datetime(self.data[\"ds\"])\n",
    "        self.data.sort_values(\"ds\", inplace=True)\n",
    "        self._scale_data()\n",
    "\n",
    "    def _model_init(self):\n",
    "        i0, i1 = self.data[\"ds\"].idxmin(), self.data[\"ds\"].idxmax()\n",
    "        T = self.data[\"t\"].iloc[i1] - self.data[\"t\"].iloc[i0]\n",
    "        slope = (self.data[\"y\"].iloc[i1] - self.data[\"y\"].iloc[i0]) / T\n",
    "        intercept = self.data[\"y\"].iloc[i0] - slope * self.data[\"t\"].iloc[i0]\n",
    "        return {\n",
    "            \"slope\": slope,\n",
    "            \"intercept\": intercept,\n",
    "            \"delta\": 0.0,\n",
    "            \"beta\": 0.0,\n",
    "            \"sigma\": 1.0,\n",
    "        }\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        data,\n",
    "        sigma_sd=0.5,\n",
    "        mcmc_samples=0,\n",
    "        chains=4,\n",
    "        cores=4,\n",
    "        use_prophet_initvals=True,\n",
    "        progressbar=True,\n",
    "    ):\n",
    "        self.mcmc_samples = mcmc_samples\n",
    "\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self._process_data()\n",
    "\n",
    "        self.initvals = {}\n",
    "        # if use_prophet_initvals:\n",
    "        #     self.initvals = self._model_init()\n",
    "\n",
    "        self.model = pm.Model()\n",
    "        self.model_idxs = {}\n",
    "        mu = self.definition(self.model, self.data, self.initvals, self.model_idxs)\n",
    "\n",
    "        with self.model:\n",
    "            sigma = pm.HalfNormal(\n",
    "                \"sigma\", sigma_sd, initval=self.initvals.get(\"sigma\", 1)\n",
    "            )\n",
    "            _ = pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=self.data[\"y\"])\n",
    "\n",
    "            self.map_approx = None\n",
    "            self.trace = None\n",
    "            if self.mcmc_samples == 0:\n",
    "                self.map_approx = pm.find_MAP(progressbar=progressbar, maxeval=1e4)\n",
    "            else:\n",
    "                self.trace = pm.sample(self.mcmc_samples, chains=chains, cores=cores)\n",
    "\n",
    "    def _make_future_df(self, days):\n",
    "        future = pd.DataFrame(\n",
    "            {\n",
    "                \"ds\": pd.DatetimeIndex(\n",
    "                    np.hstack(\n",
    "                        (\n",
    "                            self.data[\"ds\"].unique().to_numpy(),\n",
    "                            pd.date_range(\n",
    "                                self.ds_max,\n",
    "                                self.ds_max + pd.Timedelta(days, \"D\"),\n",
    "                                inclusive=\"right\",\n",
    "                            ).to_numpy(),\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        future[\"t\"] = (future[\"ds\"] - self.ds_min) / (self.ds_max - self.ds_min)\n",
    "        return future\n",
    "\n",
    "    def predict(self, days):\n",
    "        future = self._make_future_df(days)\n",
    "        forecasts = self._predict(\n",
    "            future, self.mcmc_samples, self.map_approx, self.trace\n",
    "        )\n",
    "\n",
    "        for group_code in range(forecasts.shape[0]):\n",
    "            future[f\"yhat_{group_code}\"] = forecasts[group_code] * self.y_max\n",
    "            for model_type, model_cnt in self.model_idxs.items():\n",
    "                if model_type.startswith(\"fs\"):\n",
    "                    continue\n",
    "                for model_idx in range(model_cnt):\n",
    "                    component = f\"{model_type}_{model_idx}_{group_code}\"\n",
    "                    if component in future.columns:\n",
    "                        future[component] *= self.y_max\n",
    "\n",
    "        return future\n",
    "\n",
    "    def _predict(self, future, mcmc_samples, map_approx, trace):\n",
    "        if mcmc_samples == 0:\n",
    "            return self._predict_map(future, map_approx)\n",
    "\n",
    "        return self._predict_mcmc(future, trace)\n",
    "\n",
    "    def plot(self, future, y_true=None, pool_cols=None):\n",
    "        plt.figure(figsize=(14, 100 * 6))\n",
    "        plt.subplot(100, 1, 1)\n",
    "        plt.title(\"Predictions\")\n",
    "        plt.grid()\n",
    "\n",
    "        group, _, groups_ = get_group_definition(self.data, pool_cols, \"not_complete\")\n",
    "        for group_code, group_name in groups_.items():\n",
    "            group_idx = group == group_code\n",
    "            color = np.random.rand(3)\n",
    "            plt.scatter(\n",
    "                self.data[\"ds\"][group_idx],\n",
    "                self.data[\"y\"][group_idx] * self.y_max,\n",
    "                s=0.5,\n",
    "                color=color,\n",
    "                label=group_name,\n",
    "            )\n",
    "\n",
    "        if y_true is not None:\n",
    "            test_group, _, test_groups_ = get_group_definition(\n",
    "                y_true, pool_cols, \"not_complete\"\n",
    "            )\n",
    "            for group_code, group_name in test_groups_.items():\n",
    "                group_idx = test_group == group_code\n",
    "                color = np.random.rand(3)\n",
    "                plt.scatter(\n",
    "                    y_true[\"ds\"][group_idx],\n",
    "                    y_true[\"y\"][group_idx],\n",
    "                    s=0.5,\n",
    "                    color=color,\n",
    "                    label=f\"y - {group_name}\",\n",
    "                )\n",
    "\n",
    "        for group_code, group_name in groups_.items():\n",
    "            plt.plot(\n",
    "                future[\"ds\"],\n",
    "                future[f\"yhat_{group_code}\"],\n",
    "                lw=1,\n",
    "                label=f\"yhat - {group_name}\",\n",
    "            )\n",
    "\n",
    "        plt.legend()\n",
    "        plot_params = {\"idx\": 1}\n",
    "        self._plot(plot_params, future, self.data, self.y_max, y_true)\n",
    "\n",
    "    def metrics(self, y_true, future, pool_cols=None, pool_type=\"individual\"):\n",
    "        metrics = {\"mse\": {}, \"rmse\": {}, \"mae\": {}, \"mape\": {}}\n",
    "        test_group, _, test_groups_ = get_group_definition(y_true, pool_cols, pool_type)\n",
    "        for group_code, group_name in test_groups_.items():\n",
    "            group_idx = test_group == group_code\n",
    "            y = y_true[\"y\"][group_idx]\n",
    "            yhat = future[f\"yhat_{group_code}\"][-len(y) :]\n",
    "            metrics[\"mse\"][group_name] = mean_squared_error(y, yhat)\n",
    "            metrics[\"rmse\"][group_name] = root_mean_squared_error(y, yhat)\n",
    "            metrics[\"mae\"][group_name] = mean_absolute_error(y, yhat)\n",
    "            metrics[\"mape\"][group_name] = mean_absolute_percentage_error(y, yhat)\n",
    "\n",
    "        return pd.DataFrame(metrics)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return AdditiveTimeSeries(self, other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return MultiplicativeTimeSeries(self, other)\n",
    "\n",
    "\n",
    "class AdditiveTimeSeries(TimeSeriesModel):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def definition(self, *args, **kwargs):\n",
    "        return self.left.definition(*args, **kwargs) + self.right.definition(\n",
    "            *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def _predict(self, *args, **kwargs):\n",
    "        return self.left._predict(*args, **kwargs) + self.right._predict(\n",
    "            *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def _plot(self, *args, **kwargs):\n",
    "        self.left._plot(*args, **kwargs)\n",
    "        self.right._plot(*args, **kwargs)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.left} + {self.right}\"\n",
    "\n",
    "\n",
    "class MultiplicativeTimeSeries(TimeSeriesModel):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def definition(self, *args, **kwargs):\n",
    "        return self.left.definition(*args, **kwargs) * (\n",
    "            1 + self.right.definition(*args, **kwargs)\n",
    "        )\n",
    "\n",
    "    def _predict(self, *args, **kwargs):\n",
    "        return self.left._predict(*args, **kwargs) * (\n",
    "            1 + self.right._predict(*args, **kwargs)\n",
    "        )\n",
    "\n",
    "    def _plot(self, *args, **kwargs):\n",
    "        self.left._plot(*args, **kwargs)\n",
    "        self.right._plot(*args, **kwargs)\n",
    "\n",
    "    def __str__(self):\n",
    "        left = f\"{self.left}\"\n",
    "        if type(self.left) is AdditiveTimeSeries:\n",
    "            left = f\"({self.left})\"\n",
    "\n",
    "        right = f\"{self.right}\"\n",
    "        if type(self.right) is AdditiveTimeSeries:\n",
    "            right = f\"({self.right})\"\n",
    "\n",
    "        return f\"{left} * {right}\"\n",
    "\n",
    "\n",
    "class LinearTrend(TimeSeriesModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_changepoints=25,\n",
    "        changepoint_range=0.8,\n",
    "        slope_mean=0,\n",
    "        slope_sd=5,\n",
    "        intercept_mean=0,\n",
    "        intercept_sd=5,\n",
    "        delta_mean=0,\n",
    "        delta_sd=0.05,\n",
    "        pool_cols=None,\n",
    "        pool_type=\"complete\",\n",
    "    ):\n",
    "        self.n_changepoints = n_changepoints\n",
    "        self.changepoint_range = changepoint_range\n",
    "        self.slope_mean = slope_mean\n",
    "        self.slope_sd = slope_sd\n",
    "        self.intercept_mean = intercept_mean\n",
    "        self.intercept_sd = intercept_sd\n",
    "        self.delta_mean = delta_mean\n",
    "        self.delta_sd = delta_sd\n",
    "\n",
    "        self.pool_cols = pool_cols\n",
    "        self.pool_type = pool_type\n",
    "\n",
    "    def definition(self, model, data, initvals, model_idxs):\n",
    "        model_idxs[\"lt\"] = model_idxs.get(\"lt\", 0)\n",
    "        self.model_idx = model_idxs[\"lt\"]\n",
    "        model_idxs[\"lt\"] += 1\n",
    "\n",
    "        self.group, self.n_groups, self.groups_ = get_group_definition(\n",
    "            data, self.pool_cols, self.pool_type\n",
    "        )\n",
    "\n",
    "        with model:\n",
    "            if self.pool_type == \"partial\":\n",
    "                sigma_slope = pm.HalfCauchy(\n",
    "                    f\"lt_{self.model_idx} - sigma_slope\", beta=self.slope_sd\n",
    "                )\n",
    "                offset_slope = pm.Normal(\n",
    "                    f\"lt_{self.model_idx} - offset_slope\",\n",
    "                    mu=0,\n",
    "                    sigma=1,\n",
    "                    shape=self.n_groups,\n",
    "                )\n",
    "                slope = pm.Deterministic(\n",
    "                    f\"lt_{self.model_idx} - slope\", offset_slope * sigma_slope\n",
    "                )\n",
    "\n",
    "                delta_sd = self.delta_sd\n",
    "                if self.delta_sd is None:\n",
    "                    delta_sd = pm.Exponential(f\"lt_{self.model_idx} - tau\", 1.5)\n",
    "\n",
    "                sigma_delta = pm.HalfCauchy(\n",
    "                    f\"lt_{self.model_idx} - sigma_delta\", beta=delta_sd\n",
    "                )\n",
    "                offset_delta = pm.Laplace(\n",
    "                    f\"lt_{self.model_idx} - offset_delta\",\n",
    "                    0,\n",
    "                    1,\n",
    "                    shape=(self.n_groups, self.n_changepoints),\n",
    "                )\n",
    "                delta = pm.Deterministic(\n",
    "                    f\"lt_{self.model_idx} - delta\", offset_delta * sigma_delta\n",
    "                )\n",
    "            else:\n",
    "                slope = pm.Normal(\n",
    "                    f\"lt_{self.model_idx} - slope\",\n",
    "                    self.slope_mean,\n",
    "                    self.slope_sd,\n",
    "                    initval=initvals.get(\"slope\", None),\n",
    "                    shape=self.n_groups,\n",
    "                )\n",
    "\n",
    "                delta_sd = self.delta_sd\n",
    "                if self.delta_sd is None:\n",
    "                    delta_sd = pm.Exponential(f\"lt_{self.model_idx} - tau\", 1.5)\n",
    "\n",
    "                delta = pm.Laplace(\n",
    "                    f\"lt_{self.model_idx} - delta\",\n",
    "                    self.delta_mean,\n",
    "                    delta_sd,\n",
    "                    shape=(self.n_groups, self.n_changepoints),\n",
    "                )\n",
    "\n",
    "            intercept = pm.Normal(\n",
    "                f\"lt_{self.model_idx} - intercept\",\n",
    "                self.intercept_mean,\n",
    "                self.intercept_sd,\n",
    "                initval=initvals.get(\"intercept\", None),\n",
    "                shape=self.n_groups,\n",
    "            )\n",
    "\n",
    "            if self.pool_type == \"individual\":\n",
    "                ss = []\n",
    "                t = np.array(data[\"t\"])\n",
    "                for group_code in range(self.n_groups):\n",
    "                    series_data = data[self.group == group_code]\n",
    "                    hist_size = int(\n",
    "                        np.floor(series_data.shape[0] * self.changepoint_range)\n",
    "                    )\n",
    "                    cp_indexes = (\n",
    "                        np.linspace(0, hist_size - 1, self.n_changepoints + 1)\n",
    "                        .round()\n",
    "                        .astype(int)\n",
    "                    )\n",
    "                    ss.append(np.array(series_data.iloc[cp_indexes][\"t\"].tail(-1)))\n",
    "\n",
    "                self.s = np.stack(ss, axis=0)\n",
    "                A = (t[:, None] > self.s[self.group]) * 1\n",
    "\n",
    "                gamma = -self.s[self.group, :] * delta[self.group, :]\n",
    "                trend = pm.Deterministic(\n",
    "                    f\"lt_{self.model_idx} - trend\",\n",
    "                    (slope[self.group] + pm.math.sum(A * delta[self.group], axis=1)) * t\n",
    "                    + (intercept[self.group] + pm.math.sum(A * gamma, axis=1)),\n",
    "                )\n",
    "            else:\n",
    "                t = np.array(data[\"t\"])\n",
    "                hist_size = int(np.floor(data.shape[0] * self.changepoint_range))\n",
    "                cp_indexes = (\n",
    "                    np.linspace(0, hist_size - 1, self.n_changepoints + 1)\n",
    "                    .round()\n",
    "                    .astype(int)\n",
    "                )\n",
    "                self.s = np.array(data.iloc[cp_indexes][\"t\"].tail(-1))\n",
    "                A = (t[:, None] > self.s) * 1\n",
    "\n",
    "                gamma = -self.s * delta[self.group, :]\n",
    "                trend = pm.Deterministic(\n",
    "                    f\"lt_{self.model_idx} - trend\",\n",
    "                    (slope[self.group] + pm.math.sum(A * delta[self.group], axis=1)) * t\n",
    "                    + (intercept[self.group] + pm.math.sum(A * gamma, axis=1)),\n",
    "                )\n",
    "\n",
    "        return trend\n",
    "\n",
    "    def _predict_map(self, future, map_approx):\n",
    "        forecasts = []\n",
    "        if self.pool_type != \"individual\":\n",
    "            new_A = (np.array(future[\"t\"])[:, None] > self.s) * 1\n",
    "\n",
    "        for group_code in self.groups_.keys():\n",
    "            if self.pool_type == \"individual\":\n",
    "                s = self.s[group_code]\n",
    "                new_A = (np.array(future[\"t\"])[:, None] > self.s[group_code]) * 1\n",
    "            else:\n",
    "                s = self.s\n",
    "\n",
    "            forecasts.append(\n",
    "                np.array(\n",
    "                    (\n",
    "                        map_approx[f\"lt_{self.model_idx} - slope\"][group_code]\n",
    "                        + np.dot(\n",
    "                            new_A,\n",
    "                            map_approx[f\"lt_{self.model_idx} - delta\"][group_code],\n",
    "                        )\n",
    "                    )\n",
    "                    * future[\"t\"]\n",
    "                    + (\n",
    "                        map_approx[f\"lt_{self.model_idx} - intercept\"][group_code]\n",
    "                        + np.dot(\n",
    "                            new_A,\n",
    "                            (\n",
    "                                -s\n",
    "                                * map_approx[f\"lt_{self.model_idx} - delta\"][group_code]\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            future[f\"lt_{self.model_idx}_{group_code}\"] = forecasts[-1]\n",
    "\n",
    "        return np.vstack(forecasts)\n",
    "\n",
    "    def _predict_mcmc(self, future, trace):\n",
    "        forecasts = []\n",
    "        if self.pool_type == \"individual\":\n",
    "            new_A = (np.array(future[\"t\"])[:, None] > self.s[self.group]) * 1\n",
    "        else:\n",
    "            new_A = (np.array(future[\"t\"])[:, None] > self.s) * 1\n",
    "\n",
    "        for group_code in self.groups_.keys():\n",
    "            delta = (\n",
    "                trace[\"posterior\"][f\"lt_{self.model_idx} - delta\"]\n",
    "                .to_numpy()[:, :, group_code]\n",
    "                .mean(0)\n",
    "            )\n",
    "            slope = (\n",
    "                trace[\"posterior\"][f\"lt_{self.model_idx} - slope\"]\n",
    "                .to_numpy()[:, :, group_code]\n",
    "                .mean(0)\n",
    "            )\n",
    "            intercept = (\n",
    "                trace[\"posterior\"][f\"lt_{self.model_idx} - intercept\"]\n",
    "                .to_numpy()[:, :, group_code]\n",
    "                .mean(0)\n",
    "            )\n",
    "\n",
    "            forecasts.append(\n",
    "                (\n",
    "                    (slope + np.dot(new_A, delta.T)).T * future[\"t\"].to_numpy()\n",
    "                    + (intercept + np.dot(new_A, (-self.s * delta).T)).T\n",
    "                ).mean(0)\n",
    "            )\n",
    "            future[f\"lt_{self.model_idx}_{group_code}\"] = forecasts[-1]\n",
    "\n",
    "        return np.vstack(forecasts)\n",
    "\n",
    "    def _plot(self, plot_params, future, data, y_max, y_true=None):\n",
    "        plot_params[\"idx\"] += 1\n",
    "        plt.subplot(100, 1, plot_params[\"idx\"])\n",
    "        plt.title(f\"lt_{self.model_idx}\")\n",
    "        plt.grid()\n",
    "\n",
    "        for group_code, group_name in self.groups_.items():\n",
    "            plt.plot(\n",
    "                future[\"ds\"],\n",
    "                future[f\"lt_{self.model_idx}_{group_code}\"],\n",
    "                lw=1,\n",
    "                label=group_name,\n",
    "            )\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"LT(n={self.n_changepoints},r={self.changepoint_range},{self.pool_type})\"\n",
    "\n",
    "\n",
    "class FourierSeasonality(TimeSeriesModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        period,\n",
    "        series_order,\n",
    "        beta_mean=0,\n",
    "        beta_sd=10,\n",
    "        shrinkage_strength=100,\n",
    "        pool_cols=None,\n",
    "        pool_type=\"complete\",\n",
    "    ):\n",
    "        self.period = period\n",
    "        self.series_order = series_order\n",
    "        self.beta_mean = beta_mean\n",
    "        self.beta_sd = beta_sd\n",
    "        self.shrinkage_strength = shrinkage_strength\n",
    "\n",
    "        self.pool_cols = pool_cols\n",
    "        self.pool_type = pool_type\n",
    "\n",
    "    def _fourier_series(self, data):\n",
    "        # convert to days since epoch\n",
    "        NANOSECONDS_TO_SECONDS = 1000 * 1000 * 1000\n",
    "        t = (\n",
    "            data[\"ds\"].to_numpy(dtype=np.int64)\n",
    "            // NANOSECONDS_TO_SECONDS\n",
    "            / (3600 * 24.0)\n",
    "        )\n",
    "\n",
    "        x_T = t * np.pi * 2\n",
    "        fourier_components = np.empty((data[\"ds\"].shape[0], 2 * self.series_order))\n",
    "        for i in range(self.series_order):\n",
    "            c = x_T * (i + 1) / self.period\n",
    "            fourier_components[:, 2 * i] = np.sin(c)\n",
    "            fourier_components[:, (2 * i) + 1] = np.cos(c)\n",
    "\n",
    "        return fourier_components\n",
    "\n",
    "    def definition(self, model, data, initvals, model_idxs):\n",
    "        model_idxs[\"fs\"] = model_idxs.get(\"fs\", 0)\n",
    "        self.model_idx = model_idxs[\"fs\"]\n",
    "        model_idxs[\"fs\"] += 1\n",
    "\n",
    "        group, n_groups, self.groups_ = get_group_definition(\n",
    "            data, self.pool_cols, self.pool_type\n",
    "        )\n",
    "\n",
    "        x = self._fourier_series(data)\n",
    "        beta_initval = initvals.get(\"beta\", None)\n",
    "        if beta_initval is not None:\n",
    "            beta_initval = np.array([beta_initval] * 2 * self.series_order)\n",
    "\n",
    "        with model:\n",
    "            if self.pool_type == \"partial\":\n",
    "                # shift_t = pm.Uniform(\n",
    "                #     f\"fs_{self.model_idx} - shift_t(p={self.period},n={self.series_order})\",\n",
    "                #     lower=0,\n",
    "                #     upper=self.period,\n",
    "                #     shape=n_groups,\n",
    "                # )\n",
    "                mu_beta = pm.Normal(\n",
    "                    f\"fs_{self.model_idx} - beta_mu(p={self.period},n={self.series_order})\",\n",
    "                    mu=self.beta_mean,\n",
    "                    sigma=self.beta_sd,\n",
    "                    shape=2 * self.series_order,\n",
    "                    initval=beta_initval,\n",
    "                )\n",
    "                sigma_beta = pm.HalfNormal(\n",
    "                    f\"fs_{self.model_idx} - beta_sigma(p={self.period},n={self.series_order})\",\n",
    "                    sigma=self.beta_sd / self.shrinkage_strength,\n",
    "                    shape=2 * self.series_order,\n",
    "                )\n",
    "                offset_beta = pm.Normal(\n",
    "                    f\"fs_{self.model_idx} - offset_beta(p={self.period},n={self.series_order})\",\n",
    "                    mu=0,\n",
    "                    sigma=1,\n",
    "                    shape=(n_groups, 2 * self.series_order),\n",
    "                )\n",
    "\n",
    "                beta = pm.Deterministic(\n",
    "                    f\"fs_{self.model_idx} - beta(p={self.period},n={self.series_order})\",\n",
    "                    mu_beta + offset_beta * sigma_beta,\n",
    "                )\n",
    "            else:\n",
    "                beta = pm.Normal(\n",
    "                    f\"fs_{self.model_idx} - beta(p={self.period},n={self.series_order})\",\n",
    "                    mu=self.beta_mean,\n",
    "                    sigma=self.beta_sd,\n",
    "                    shape=(n_groups, 2 * self.series_order),\n",
    "                    initval=beta_initval,\n",
    "                )\n",
    "\n",
    "        return pm.math.sum(x * beta[group], axis=1)\n",
    "\n",
    "    def _det_seasonality_posterior(self, beta, x):\n",
    "        return np.dot(x, beta.T)\n",
    "\n",
    "    def _predict_map(self, future, map_approx):\n",
    "        forecasts = []\n",
    "        for group_code in self.groups_.keys():\n",
    "            forecasts.append(\n",
    "                self._det_seasonality_posterior(\n",
    "                    map_approx[\n",
    "                        f\"fs_{self.model_idx} - beta(p={self.period},n={self.series_order})\"\n",
    "                    ][group_code],\n",
    "                    self._fourier_series(future),\n",
    "                )\n",
    "            )\n",
    "            future[f\"fs_{self.model_idx}_{group_code}\"] = forecasts[-1]\n",
    "\n",
    "        return np.vstack(forecasts)\n",
    "\n",
    "    def _predict_mcmc(self, future, trace):\n",
    "        forecasts = []\n",
    "        for group_code in self.groups_.keys():\n",
    "            forecasts.append(\n",
    "                self._det_seasonality_posterior(\n",
    "                    trace[\"posterior\"][\n",
    "                        f\"fs_{self.model_idx} - beta(p={self.period},n={self.series_order})\"\n",
    "                    ]\n",
    "                    .to_numpy()[:, :, group_code]\n",
    "                    .mean(0),\n",
    "                    self._fourier_series(future),\n",
    "                ).T.mean(0)\n",
    "            )\n",
    "            future[f\"fs_{self.model_idx}_{group_code}\"] = forecasts[-1]\n",
    "\n",
    "        return np.vstack(forecasts)\n",
    "\n",
    "    def _plot(self, plot_params, future, data, y_max, y_true=None):\n",
    "        date = future[\"ds\"] if self.period > 7 else future[\"ds\"].dt.day_name()\n",
    "        plot_params[\"idx\"] += 1\n",
    "        plt.subplot(100, 1, plot_params[\"idx\"])\n",
    "        plt.title(f\"fs_{self.model_idx} - p={self.period},n={self.series_order}\")\n",
    "        plt.grid()\n",
    "\n",
    "        for group_code, group_name in self.groups_.items():\n",
    "            plt.plot(\n",
    "                date[-int(self.period) :],\n",
    "                future[f\"fs_{self.model_idx}_{group_code}\"][-int(self.period) :],\n",
    "                lw=1,\n",
    "                label=group_name,\n",
    "            )\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"FS(p={self.period},n={self.series_order},{self.pool_type})\"\n",
    "\n",
    "\n",
    "class Constant(TimeSeriesModel):\n",
    "    def __init__(self, lower, upper, pool_cols=None, pool_type=\"complete\"):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.pool_cols = pool_cols\n",
    "        self.pool_type = pool_type\n",
    "\n",
    "    def definition(self, model, data, initvals, model_idxs):\n",
    "        model_idxs[\"c\"] = model_idxs.get(\"c\", 0)\n",
    "        self.model_idx = model_idxs[\"c\"]\n",
    "        model_idxs[\"c\"] += 1\n",
    "\n",
    "        group, n_groups, self.groups_ = get_group_definition(\n",
    "            data, self.pool_cols, self.pool_type\n",
    "        )\n",
    "\n",
    "        with model:\n",
    "            if self.pool_type == \"partial\":\n",
    "                mu_c = pm.Uniform(\n",
    "                    f\"c_{self.model_idx} - mu_c(l={self.lower},u={self.upper})\",\n",
    "                    lower=self.lower,\n",
    "                    upper=self.upper,\n",
    "                    shape=n_groups,\n",
    "                )\n",
    "                offset_c = pm.Normal(\n",
    "                    f\"c_{self.model_idx} - offset_c(l={self.lower},u={self.upper})\",\n",
    "                    mu=0,\n",
    "                    sigma=1,\n",
    "                    shape=n_groups,\n",
    "                )\n",
    "                c = pm.Deterministic(\n",
    "                    f\"c_{self.model_idx} - c(l={self.lower},u={self.upper})\",\n",
    "                    mu_c + offset_c,\n",
    "                )\n",
    "            else:\n",
    "                c = pm.Uniform(\n",
    "                    f\"c_{self.model_idx} - c(l={self.lower},u={self.upper})\",\n",
    "                    lower=self.lower,\n",
    "                    upper=self.upper,\n",
    "                    shape=n_groups,\n",
    "                )\n",
    "\n",
    "        return c[group]\n",
    "\n",
    "    def _predict_map(self, future, map_approx):\n",
    "        forecasts = []\n",
    "        for group_code in self.groups_.keys():\n",
    "            forecasts.append(\n",
    "                np.ones_like(future[\"t\"])\n",
    "                * map_approx[f\"c_{self.model_idx} - c(l={self.lower},u={self.upper})\"][\n",
    "                    group_code\n",
    "                ]\n",
    "            )\n",
    "            future[f\"c_{self.model_idx}_{group_code}\"] = forecasts[-1]\n",
    "\n",
    "        return np.vstack(forecasts)\n",
    "\n",
    "    def _predict_mcmc(self, future, trace):\n",
    "        forecasts = []\n",
    "        for group_code in self.groups_.keys():\n",
    "            forecasts.append(\n",
    "                np.ones_like(future[\"t\"])\n",
    "                * trace[\"posterior\"][\n",
    "                    f\"c_{self.model_idx} - c(l={self.lower},u={self.upper})\"\n",
    "                ]\n",
    "                .to_numpy()[:, :, group_code]\n",
    "                .mean()\n",
    "            )\n",
    "            future[f\"c_{self.model_idx}_{group_code}\"] = forecasts[-1]\n",
    "\n",
    "        return np.vstack(forecasts)\n",
    "\n",
    "    def _plot(self, plot_params, future, data, y_max, y_true=None):\n",
    "        plot_params[\"idx\"] += 1\n",
    "        plt.subplot(100, 1, plot_params[\"idx\"])\n",
    "        plt.title(f\"c_{self.model_idx} - c(l={self.lower},u={self.upper})\")\n",
    "\n",
    "        plot_data = []\n",
    "        for group_code, group_name in self.groups_.items():\n",
    "            plot_data.append(\n",
    "                (group_name, future[f\"c_{self.model_idx}_{group_code}\"][0])\n",
    "            )\n",
    "\n",
    "        plt.bar(*zip(*plot_data))\n",
    "        plt.axhline(0, c=\"k\", linewidth=3)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"C(l={self.lower},u={self.upper},{self.pool_type})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [\"^W5000\", \"^GSPC\", \"^IXIC\", \"^DJI\"]\n",
    "\n",
    "gspc_tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"AMZN\", \"FB\", \"TSLA\", \"GOOGL\", \"GOOG\", \"JNJ\", \"JPM\", \"V\",\n",
    "    \"PG\", \"UNH\", \"DIS\", \"NVDA\", \"MA\", \"HD\", \"PYPL\", \"VZ\", \"ADBE\", \"CMCSA\",\n",
    "    \"NFLX\", \"BAC\", \"KO\", \"MRK\", \"PEP\", \"T\", \"PFE\", \"INTC\", \"CRM\", \"WMT\", \"ABT\",\n",
    "    \"ABBV\", \"CSCO\", \"TMO\", \"NKE\", \"AVGO\", \"XOM\", \"QCOM\", \"COST\", \"ACN\", \"CVX\",\n",
    "    \"MCD\", \"MDT\", \"NEE\", \"TXN\", \"HON\", \"DHR\", \"UNP\", \"BMY\", \"LIN\", \"LLY\",\n",
    "    \"AMGN\", \"PM\", \"C\", \"SBUX\", \"WFC\", \"ORCL\", \"UPS\", \"LOW\", \"BA\", \"IBM\", \"AMD\",\n",
    "    \"RTX\", \"NOW\", \"BLK\", \"MMM\", \"INTU\", \"AMT\", \"CAT\", \"MS\", \"CHTR\", \"ISRG\",\n",
    "    \"GE\", \"BKNG\", \"GS\", \"CVS\", \"TGT\", \"FIS\", \"LMT\", \"DE\", \"MU\", \"MDLZ\", \"TJX\",\n",
    "    \"SYK\", \"ANTM\", \"SCHW\", \"SPGI\", \"AXP\", \"AMAT\", \"TMUS\", \"ZTS\", \"MO\", \"ADP\",\n",
    "    \"CI\", \"PLD\", \"CL\", \"GILD\", \"BDX\", \"ATVI\", \"CB\", \"CSX\", \"CCI\", \"LRCX\",\n",
    "    \"DUK\", \"ADSK\", \"FISV\", \"CME\", \"SO\", \"ICE\", \"TFC\", \"GPN\", \"USB\", \"EQIX\",\n",
    "    \"PNC\", \"FDX\", \"VRTX\", \"D\", \"APD\", \"NSC\", \"EL\", \"SHW\", \"MMC\", \"ITW\", \"PGR\",\n",
    "    \"EW\", \"ADI\", \"HUM\", \"ILMN\", \"ECL\", \"GM\", \"DD\", \"DG\", \"BSX\", \"REGN\", \"AON\",\n",
    "    \"NEM\", \"EMR\", \"ETN\", \"NOC\", \"MCO\", \"KMB\", \"WM\", \"COF\", \"ROP\", \"CTSH\",\n",
    "    \"ROST\", \"HCA\", \"TWTR\", \"COP\", \"IDXX\", \"EA\", \"AEP\", \"EXC\", \"DOW\", \"BAX\",\n",
    "    \"TEL\", \"KLAC\", \"LHX\", \"SNPS\", \"APH\", \"DLR\", \"CMG\", \"ALGN\", \"CDNS\", \"SYY\",\n",
    "    \"FCX\", \"BIIB\", \"STZ\", \"MSCI\", \"SRE\", \"A\", \"MCHP\", \"GIS\", \"MET\", \"TRV\",\n",
    "    \"DXCM\", \"APTV\", \"PSA\", \"PH\", \"MAR\", \"XEL\", \"TT\", \"CNC\", \"XLNX\", \"GD\", \"BK\",\n",
    "    \"F\", \"IQV\", \"TROW\", \"ALXN\", \"MNST\", \"PPG\", \"HPQ\", \"VRSK\", \"JCI\", \"TDG\",\n",
    "    \"CMI\", \"INFO\", \"ALL\", \"EBAY\", \"ORLY\", \"YUM\", \"AIG\", \"ZBH\", \"SBAC\", \"ANSS\",\n",
    "    \"CTAS\", \"PRU\", \"HLT\", \"RMD\", \"CARR\", \"PSX\", \"BLL\", \"SLB\", \"PCAR\", \"PAYX\",\n",
    "    \"ES\", \"PEG\", \"ROK\", \"EOG\", \"AFL\", \"WEC\", \"CTVA\", \"MSI\", \"WBA\", \"SWK\",\n",
    "    \"ADM\", \"FAST\", \"SPG\", \"MCK\", \"AME\", \"AWK\", \"DFS\", \"LUV\", \"OTIS\", \"GLW\",\n",
    "    \"AZO\", \"VFC\", \"WLTW\", \"MTD\", \"WELL\", \"MPC\", \"KMI\", \"CPRT\", \"STT\", \"DAL\",\n",
    "    \"FRC\", \"CLX\", \"DLTR\", \"SWKS\", \"WY\", \"ED\", \"KR\", \"KEYS\", \"WMB\", \"CERN\",\n",
    "    \"TTWO\", \"FTV\", \"AJG\", \"EIX\", \"MKC\", \"MXIM\", \"LYB\", \"DTE\", \"EFX\", \"VLO\",\n",
    "    \"BBY\", \"AMP\", \"DHI\", \"FLT\", \"VTRS\", \"HSY\", \"KHC\", \"AVB\", \"PAYC\", \"ETSY\",\n",
    "    \"O\", \"VRSN\", \"PPL\", \"CHD\", \"MKTX\", \"ARE\", \"VIAC\", \"CBRE\", \"LEN\", \"WST\",\n",
    "    \"ZBRA\", \"EQR\", \"RSG\", \"SIVB\", \"FTNT\", \"ETR\", \"TER\", \"LH\", \"VMC\", \"FITB\",\n",
    "    \"LVS\", \"IP\", \"NTRS\", \"AEE\", \"TFX\", \"KSU\", \"QRVO\", \"TSN\", \"SYF\", \"CDW\",\n",
    "    \"ODFL\", \"PXD\", \"HOLX\", \"AMCR\", \"GWW\", \"VTR\", \"XYL\", \"DOV\", \"EXPE\", \"GRMN\",\n",
    "    \"COO\", \"CAG\", \"BR\", \"MLM\", \"TYL\", \"HIG\", \"CMS\", \"CTLT\", \"AKAM\", \"OKE\",\n",
    "    \"IR\", \"WDC\", \"URI\", \"HAL\", \"FE\", \"TSCO\", \"MTB\", \"PEAK\", \"INCY\", \"ULTA\",\n",
    "    \"STE\", \"CCL\", \"EXPD\", \"PKI\", \"NUE\", \"DGX\", \"KEY\", \"CTXS\", \"VAR\", \"K\",\n",
    "    \"ANET\", \"CAH\", \"ALB\", \"AES\", \"DRI\", \"KMX\", \"RF\", \"ESS\", \"WAT\", \"CFG\",\n",
    "    \"HPE\", \"NDAQ\", \"CE\", \"DPZ\", \"IEX\", \"EXR\", \"POOL\", \"FMC\", \"DRE\", \"NTAP\",\n",
    "    \"ABMD\", \"OXY\", \"MAA\", \"GPC\", \"TDY\", \"HES\", \"ABC\", \"MAS\", \"IT\", \"NVR\",\n",
    "    \"TIF\", \"J\", \"LDOS\", \"BKR\", \"STX\", \"RCL\", \"EMN\", \"OMC\", \"BXP\", \"SJM\", \"WAB\",\n",
    "    \"HRL\", \"PKG\", \"CINF\", \"AVY\", \"MGM\", \"LNT\", \"HBAN\", \"CHRW\", \"PFG\", \"UAL\",\n",
    "    \"EVRG\", \"BIO\", \"JKHY\", \"NLOK\", \"HAS\", \"ATO\", \"FBHS\", \"CNP\", \"RJF\", \"IFF\",\n",
    "    \"PHM\", \"LW\", \"CXO\", \"XRAY\", \"WRK\", \"JBHT\", \"UDR\", \"WHR\", \"HWM\", \"TXT\",\n",
    "    \"WYNN\", \"FFIV\", \"ALLE\", \"AAP\", \"UHS\", \"L\", \"LYV\", \"HST\", \"CBOE\", \"PWR\",\n",
    "    \"LKQ\", \"FOXA\", \"CPB\", \"AAL\", \"LUMN\", \"HSIC\", \"BWA\", \"RE\", \"WRB\", \"SNA\",\n",
    "    \"IPG\", \"NRG\", \"GL\", \"LNC\", \"WU\", \"PNW\", \"PNR\", \"NI\", \"LB\", \"DVA\", \"ROL\",\n",
    "    \"TPR\", \"TAP\", \"IRM\", \"MHK\", \"CF\", \"AIZ\", \"NCLH\", \"NWL\", \"DISH\", \"IPGP\",\n",
    "    \"MOS\", \"CMA\", \"DISCK\", \"FANG\", \"NLSN\", \"AOS\", \"JNPR\", \"REG\", \"ZION\", \"RHI\",\n",
    "    \"SEE\", \"NWSA\", \"HII\", \"BEN\", \"PVH\", \"IVZ\", \"DXC\", \"COG\", \"KIM\", \"ALK\",\n",
    "    \"PRGO\", \"DVN\", \"LEG\", \"FRT\", \"VNO\", \"FLIR\", \"PBCT\", \"APA\", \"NOV\", \"MRO\",\n",
    "    \"HBI\", \"RL\", \"DISCA\", \"FLS\", \"UNM\", \"VNT\", \"FOX\", \"SLG\", \"GPS\", \"FTI\",\n",
    "    \"XRX\", \"HFC\", \"UAA\", \"UA\", \"NWS\"\n",
    "]\n",
    "\n",
    "dji_tickers = [\n",
    "    \"DIS\", \"WMT\", \"DOW\", \"NKE\", \"CRM\", \"HD\", \"V\", \"MSFT\", \"MMM\", \"CSCO\", \"KO\",\n",
    "    \"AAPL\", \"HON\", \"JNJ\", \"TRV\", \"PG\", \"CVX\", \"VZ\", \"CAT\", \"BA\", \"AMGN\", \"IBM\",\n",
    "    \"AXP\", \"JPM\", \"WBA\", \"MCD\", \"MRK\", \"GS\", \"UNH\", \"INTC\"\n",
    "]\n",
    "\n",
    "ixic_tickers = [\n",
    "    \"FEYE\", \"ATEC\", \"SLAB\", \"CMRX\", \"NVCR\", \"FNLC\", \"NMRK\", \"SCOR\", \"AGLE\",\n",
    "    \"FARO\", \"OLMA\", \"TSLA\", \"FRTA\", \"AKTX\", \"KLXE\", \"CVCO\", \"NVCN\", \"EXAS\",\n",
    "    \"SDC\", \"BBQ\", \"IFRX\", \"CIIC\", \"BBI\", \"FNKO\", \"TWST\", \"FARM\", \"ACCD\",\n",
    "    \"NMRD\", \"FRSX\", \"OPTT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(tickers, start=\"1970-01-01\", end=\"2020-01-01\"):\n",
    "    data = yfinance.download(\n",
    "        tickers,\n",
    "        interval=\"1d\",\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    downloaded_tickers = {col[1] for col in data.columns}\n",
    "    dfs = []\n",
    "    for ticker in downloaded_tickers:\n",
    "        df = pd.DataFrame(\n",
    "            data={\n",
    "                \"open\": data[\"Open\"][ticker].to_numpy(),\n",
    "                \"high\": data[\"High\"][ticker].to_numpy(),\n",
    "                \"low\": data[\"Low\"][ticker].to_numpy(),\n",
    "                \"close\": data[\"Close\"][ticker].to_numpy(),\n",
    "                \"typical_price\": (\n",
    "                    (\n",
    "                        data[\"Open\"][ticker]\n",
    "                        + data[\"High\"][ticker]\n",
    "                        + data[\"Low\"][ticker]\n",
    "                        + data[\"Close\"][ticker]\n",
    "                    )\n",
    "                    / 4\n",
    "                ).to_numpy(),\n",
    "                \"volume\": data[\"Volume\"][ticker].to_numpy(),\n",
    "            },\n",
    "            index=data[\"Close\"][ticker].index,\n",
    "        )\n",
    "\n",
    "        full_date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq=\"D\")\n",
    "        df = df.reindex(full_date_range).interpolate()\n",
    "        df[\"ds\"] = df.index\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df[\"series\"] = ticker\n",
    "        dfs.append(df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_df(\n",
    "    start,\n",
    "    window,\n",
    "    horizon,\n",
    "    dfs,\n",
    "    for_prophet=False,\n",
    "    y_col=\"typical_price\",\n",
    "    perform_scaling=True,\n",
    "):\n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    scales = []\n",
    "    for df in dfs:\n",
    "        train_df = df[start : start + window].copy()\n",
    "        test_df = df[start + window : start + window + horizon].copy()\n",
    "        if train_df.isna().any().any() or test_df.isna().any().any():\n",
    "            continue\n",
    "\n",
    "        train_df[\"y\"] = train_df[y_col]\n",
    "        test_df[\"y\"] = test_df[y_col]\n",
    "\n",
    "        if perform_scaling:\n",
    "            scales.append(train_df[y_col].max())\n",
    "            train_df[\"y\"] = train_df[y_col] / scales[-1]\n",
    "            test_df[\"y\"] = test_df[y_col] / scales[-1]\n",
    "\n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "\n",
    "    if len(train_dfs) == 0:\n",
    "        return None\n",
    "\n",
    "    if for_prophet:\n",
    "        return train_dfs, test_dfs, scales\n",
    "\n",
    "    return pd.concat(train_dfs), pd.concat(test_dfs), scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_df_around_point(\n",
    "    window,\n",
    "    horizon,\n",
    "    dfs,\n",
    "    point=\"2009-09-01\",\n",
    "    for_prophet=False,\n",
    "    y_col=\"typical_price\",\n",
    "    perform_scaling=True,\n",
    "):\n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    scales = []\n",
    "\n",
    "    for df in dfs:\n",
    "        point_idx = len(df[df[\"ds\"] < point])\n",
    "        check = generate_train_test_df(\n",
    "            start=point_idx - window,\n",
    "            window=window,\n",
    "            horizon=horizon,\n",
    "            dfs=[df],\n",
    "            for_prophet=for_prophet,\n",
    "            y_col=y_col,\n",
    "            perform_scaling=perform_scaling,\n",
    "        )\n",
    "        if check is None:\n",
    "            continue\n",
    "\n",
    "        train_df, test_df, scale = check\n",
    "\n",
    "        scales += scale\n",
    "\n",
    "        if for_prophet:\n",
    "            train_dfs += train_df\n",
    "            test_dfs += test_df\n",
    "        else:\n",
    "            train_dfs.append(train_df)\n",
    "            test_dfs.append(test_df)\n",
    "\n",
    "    if len(train_dfs) == 0:\n",
    "        return None\n",
    "    \n",
    "    if for_prophet:\n",
    "        return train_dfs, test_dfs, scales\n",
    "    \n",
    "    return pd.concat(train_dfs), pd.concat(test_dfs), scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_components = [\n",
    "    [LinearTrend(pool_cols=\"series\", pool_type=pt) for pt in [\"individual\", \"partial\"]],\n",
    "    [\n",
    "        FourierSeasonality(\n",
    "            period=365.25, series_order=10, pool_cols=\"series\", pool_type=pt\n",
    "        )\n",
    "        for pt in [\"individual\", \"partial\"]\n",
    "    ],\n",
    "    [\n",
    "        FourierSeasonality(\n",
    "            period=91.3125, series_order=n, pool_cols=\"series\", pool_type=pt\n",
    "        )\n",
    "        for n in range(7, 10)\n",
    "        for pt in [\"individual\", \"partial\"]\n",
    "    ],\n",
    "    [\n",
    "        FourierSeasonality(\n",
    "            period=30.4375, series_order=n, pool_cols=\"series\", pool_type=pt\n",
    "        )\n",
    "        for n in range(4, 7)\n",
    "        for pt in [\"individual\", \"partial\"]\n",
    "    ],\n",
    "    [\n",
    "        FourierSeasonality(\n",
    "            period=7, series_order=3, pool_cols=\"series\", pool_type=pt\n",
    "        )\n",
    "        for pt in [\"individual\", \"partial\"]\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [(0, [mc]) for mc in model_components[0]]\n",
    "models = []\n",
    "\n",
    "while len(q):\n",
    "    level, model = q.pop(0)\n",
    "    if level + 1 == len(model_components):\n",
    "        models.append(model)\n",
    "        continue\n",
    "\n",
    "    mcs = model_components[level + 1]\n",
    "    for mc in mcs:\n",
    "        # if mc.pool_type == \"partial\":\n",
    "        #     q.append(\n",
    "        #         (\n",
    "        #             level + 1,\n",
    "        #             model\n",
    "        #             + [\n",
    "        #                 Constant(\n",
    "        #                     lower=-1, upper=1, pool_cols=\"series\", pool_type=\"partial\"\n",
    "        #                 )\n",
    "        #                 * mc\n",
    "        #             ],\n",
    "        #         )\n",
    "        #     )\n",
    "\n",
    "        q.append((level + 1, model + [mc]))\n",
    "        q.append((level + 1, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_models(models):\n",
    "    s = None\n",
    "    for model in models:\n",
    "        if s is None:\n",
    "            s = model\n",
    "        else:\n",
    "            s += model\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model[0] * sum_models(model[1:]) if len(model) > 1 else model[0] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_models = {\"\"}\n",
    "final_models = []\n",
    "for model in models:\n",
    "    str_model = str(model)\n",
    "    if str_model in str_models:\n",
    "        continue\n",
    "\n",
    "    str_models.add(str_model)\n",
    "    final_models.append(model)\n",
    "\n",
    "len(final_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prophet_metrics(y_trues, y_preds, horizon):\n",
    "    result = None\n",
    "    for y_true, y_pred in zip(y_trues, y_preds):\n",
    "        group_name = y_true[\"series\"].iloc[0]\n",
    "        single_metrics = {\"mse\": {}, \"rmse\": {}, \"mae\": {}, \"mape\": {}}\n",
    "        single_metrics[\"mse\"][group_name] = mean_squared_error(\n",
    "            y_true[\"y\"], y_pred[\"yhat\"][-horizon:]\n",
    "        )\n",
    "        single_metrics[\"rmse\"][group_name] = root_mean_squared_error(\n",
    "            y_true[\"y\"], y_pred[\"yhat\"][-horizon:]\n",
    "        )\n",
    "        single_metrics[\"mae\"][group_name] = mean_absolute_error(\n",
    "            y_true[\"y\"], y_pred[\"yhat\"][-horizon:]\n",
    "        )\n",
    "        single_metrics[\"mape\"][group_name] = mean_absolute_percentage_error(\n",
    "            y_true[\"y\"], y_pred[\"yhat\"][-horizon:]\n",
    "        )\n",
    "        if result is None:\n",
    "            result = pd.DataFrame(single_metrics)\n",
    "        else:\n",
    "            result = pd.concat((result, pd.DataFrame(single_metrics)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  503 of 503 completed\n",
      "\n",
      "83 Failed downloads:\n",
      "['INFO', 'CARR', 'KEYS', 'PYPL', 'HII', 'DOW', 'ABBV', 'CFG', 'CTVA', 'NCLH', 'FTV', 'FANG', 'LW', 'FISV', 'MPC', 'IQV', 'PAYC', 'HCA', 'ETSY', 'OTIS', 'IR', 'HLT', 'PSX', 'QRVO', 'FOXA', 'ALLE', 'ANET', 'SYF', 'HPE', 'NWSA', 'FOX', 'CTLT', 'KMI', 'AMCR', 'LB', 'ZTS', 'HWM', 'VNT', 'XYL', 'NWS', 'CDW', 'UA', 'KHC', 'NOW', 'APTV']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2008-01-01 -> 2011-01-01) (Yahoo error = \"Data doesn\\'t exist for startDate = 1199163600, endDate = 1293858000\")')\n",
      "['HFC', 'TIF', 'KSU', 'PEAK', 'CTXS', 'NLSN', 'GPS', 'NLOK', 'DRE', 'FRC', 'MXIM', 'PBCT', 'SIVB', 'FLT', 'FB', 'TWTR', 'ABC', 'ALXN', 'FLIR', 'RE', 'DISCK', 'ANTM', 'COG', 'ATVI', 'PXD', 'PKI', 'CERN', 'DISH', 'XLNX', 'ABMD', 'WRK', 'DISCA', 'WLTW', 'CXO', 'VAR', 'VIAC', 'BLL', 'FBHS']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
     ]
    }
   ],
   "source": [
    "smp = fetch_data([\"^GSPC\"])\n",
    "smp_tickers = fetch_data(gspc_tickers, start=\"2008-01-01\", end=\"2011-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_smp, test_df_smp, scales_smp = generate_train_test_df_around_point(\n",
    "    window=365 * 35, horizon=365, dfs=smp, for_prophet=True\n",
    ")\n",
    "train_df_ticker, test_df_tickers, scales_tickers = generate_train_test_df_around_point(\n",
    "    window=365 * 1, horizon=365, dfs=smp + smp_tickers, for_prophet=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>typical_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>ds</th>\n",
       "      <th>series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.147324</td>\n",
       "      <td>65.212950</td>\n",
       "      <td>62.357990</td>\n",
       "      <td>62.694347</td>\n",
       "      <td>63.853153</td>\n",
       "      <td>2.301300e+06</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.079946</td>\n",
       "      <td>63.399898</td>\n",
       "      <td>60.733624</td>\n",
       "      <td>60.971539</td>\n",
       "      <td>62.046252</td>\n",
       "      <td>1.775000e+06</td>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.709001</td>\n",
       "      <td>60.709001</td>\n",
       "      <td>58.231420</td>\n",
       "      <td>58.256031</td>\n",
       "      <td>59.476363</td>\n",
       "      <td>1.899400e+06</td>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.085504</td>\n",
       "      <td>60.610554</td>\n",
       "      <td>57.810286</td>\n",
       "      <td>58.256031</td>\n",
       "      <td>59.190594</td>\n",
       "      <td>2.166067e+06</td>\n",
       "      <td>2008-01-05</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.462006</td>\n",
       "      <td>60.512107</td>\n",
       "      <td>57.389151</td>\n",
       "      <td>58.256031</td>\n",
       "      <td>58.904824</td>\n",
       "      <td>2.432733e+06</td>\n",
       "      <td>2008-01-06</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>40.124209</td>\n",
       "      <td>40.204978</td>\n",
       "      <td>39.594723</td>\n",
       "      <td>39.872929</td>\n",
       "      <td>39.949210</td>\n",
       "      <td>8.238000e+05</td>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>40.061359</td>\n",
       "      <td>40.061359</td>\n",
       "      <td>39.558799</td>\n",
       "      <td>39.783157</td>\n",
       "      <td>39.866169</td>\n",
       "      <td>6.349000e+05</td>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>39.926763</td>\n",
       "      <td>40.680606</td>\n",
       "      <td>39.890865</td>\n",
       "      <td>40.537014</td>\n",
       "      <td>40.258812</td>\n",
       "      <td>9.381000e+05</td>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>40.402391</td>\n",
       "      <td>40.519058</td>\n",
       "      <td>40.124186</td>\n",
       "      <td>40.231880</td>\n",
       "      <td>40.319379</td>\n",
       "      <td>8.673000e+05</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>40.115208</td>\n",
       "      <td>40.303668</td>\n",
       "      <td>39.657516</td>\n",
       "      <td>39.810081</td>\n",
       "      <td>39.971619</td>\n",
       "      <td>8.669000e+05</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>VMC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open       high        low      close  typical_price        volume  \\\n",
       "0     65.147324  65.212950  62.357990  62.694347      63.853153  2.301300e+06   \n",
       "1     63.079946  63.399898  60.733624  60.971539      62.046252  1.775000e+06   \n",
       "2     60.709001  60.709001  58.231420  58.256031      59.476363  1.899400e+06   \n",
       "3     60.085504  60.610554  57.810286  58.256031      59.190594  2.166067e+06   \n",
       "4     59.462006  60.512107  57.389151  58.256031      58.904824  2.432733e+06   \n",
       "...         ...        ...        ...        ...            ...           ...   \n",
       "1090  40.124209  40.204978  39.594723  39.872929      39.949210  8.238000e+05   \n",
       "1091  40.061359  40.061359  39.558799  39.783157      39.866169  6.349000e+05   \n",
       "1092  39.926763  40.680606  39.890865  40.537014      40.258812  9.381000e+05   \n",
       "1093  40.402391  40.519058  40.124186  40.231880      40.319379  8.673000e+05   \n",
       "1094  40.115208  40.303668  39.657516  39.810081      39.971619  8.669000e+05   \n",
       "\n",
       "             ds series  \n",
       "0    2008-01-02    VMC  \n",
       "1    2008-01-03    VMC  \n",
       "2    2008-01-04    VMC  \n",
       "3    2008-01-05    VMC  \n",
       "4    2008-01-06    VMC  \n",
       "...         ...    ...  \n",
       "1090 2010-12-27    VMC  \n",
       "1091 2010-12-28    VMC  \n",
       "1092 2010-12-29    VMC  \n",
       "1093 2010-12-30    VMC  \n",
       "1094 2010-12-31    VMC  \n",
       "\n",
       "[1095 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smp_tickers[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prophet = Prophet(seasonality_mode=\"multiplicative\")\n",
    "context_prophet.fit(train_df_smp[0])\n",
    "context_future = context_prophet.make_future_dataframe(\n",
    "    periods=365, include_history=True\n",
    ")\n",
    "context_yhat = context_prophet.predict(context_future)\n",
    "context_metrics = get_prophet_metrics(test_df_smp, [context_yhat], 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974-09-10</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>-0.043104</td>\n",
       "      <td>0.120550</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1974-09-11</td>\n",
       "      <td>0.038966</td>\n",
       "      <td>-0.035904</td>\n",
       "      <td>0.114587</td>\n",
       "      <td>0.038966</td>\n",
       "      <td>0.038966</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1974-09-12</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>-0.034947</td>\n",
       "      <td>0.115029</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1974-09-13</td>\n",
       "      <td>0.038980</td>\n",
       "      <td>-0.037401</td>\n",
       "      <td>0.111246</td>\n",
       "      <td>0.038980</td>\n",
       "      <td>0.038980</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1974-09-14</td>\n",
       "      <td>0.038987</td>\n",
       "      <td>-0.036805</td>\n",
       "      <td>0.112612</td>\n",
       "      <td>0.038987</td>\n",
       "      <td>0.038987</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13135</th>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>0.769250</td>\n",
       "      <td>0.923119</td>\n",
       "      <td>0.832547</td>\n",
       "      <td>0.856717</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>2010-08-28</td>\n",
       "      <td>0.843753</td>\n",
       "      <td>0.773151</td>\n",
       "      <td>0.923987</td>\n",
       "      <td>0.832567</td>\n",
       "      <td>0.856852</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13137</th>\n",
       "      <td>2010-08-29</td>\n",
       "      <td>0.843812</td>\n",
       "      <td>0.770309</td>\n",
       "      <td>0.929036</td>\n",
       "      <td>0.832588</td>\n",
       "      <td>0.857085</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13138</th>\n",
       "      <td>2010-08-30</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.776397</td>\n",
       "      <td>0.924557</td>\n",
       "      <td>0.832554</td>\n",
       "      <td>0.857277</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13139</th>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>0.843931</td>\n",
       "      <td>0.775778</td>\n",
       "      <td>0.926875</td>\n",
       "      <td>0.832478</td>\n",
       "      <td>0.857386</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13140 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ds     trend  yhat_lower  yhat_upper  trend_lower  trend_upper  \\\n",
       "0     1974-09-10  0.038959   -0.043104    0.120550     0.038959     0.038959   \n",
       "1     1974-09-11  0.038966   -0.035904    0.114587     0.038966     0.038966   \n",
       "2     1974-09-12  0.038973   -0.034947    0.115029     0.038973     0.038973   \n",
       "3     1974-09-13  0.038980   -0.037401    0.111246     0.038980     0.038980   \n",
       "4     1974-09-14  0.038987   -0.036805    0.112612     0.038987     0.038987   \n",
       "...          ...       ...         ...         ...          ...          ...   \n",
       "13135 2010-08-27  0.843693    0.769250    0.923119     0.832547     0.856717   \n",
       "13136 2010-08-28  0.843753    0.773151    0.923987     0.832567     0.856852   \n",
       "13137 2010-08-29  0.843812    0.770309    0.929036     0.832588     0.857085   \n",
       "13138 2010-08-30  0.843871    0.776397    0.924557     0.832554     0.857277   \n",
       "13139 2010-08-31  0.843931    0.775778    0.926875     0.832478     0.857386   \n",
       "\n",
       "       multiplicative_terms  multiplicative_terms_lower  \\\n",
       "0                  0.008546                    0.008546   \n",
       "1                  0.008378                    0.008378   \n",
       "2                  0.008072                    0.008072   \n",
       "3                  0.007747                    0.007747   \n",
       "4                  0.007298                    0.007298   \n",
       "...                     ...                         ...   \n",
       "13135              0.005093                    0.005093   \n",
       "13136              0.005574                    0.005574   \n",
       "13137              0.006008                    0.006008   \n",
       "13138              0.006394                    0.006394   \n",
       "13139              0.007191                    0.007191   \n",
       "\n",
       "       multiplicative_terms_upper    weekly  weekly_lower  weekly_upper  \\\n",
       "0                        0.008546  0.000146      0.000146      0.000146   \n",
       "1                        0.008378  0.000148      0.000148      0.000148   \n",
       "2                        0.008072  0.000073      0.000073      0.000073   \n",
       "3                        0.007747  0.000042      0.000042      0.000042   \n",
       "4                        0.007298 -0.000047     -0.000047     -0.000047   \n",
       "...                           ...       ...           ...           ...   \n",
       "13135                    0.005093  0.000042      0.000042      0.000042   \n",
       "13136                    0.005574 -0.000047     -0.000047     -0.000047   \n",
       "13137                    0.006008 -0.000137     -0.000137     -0.000137   \n",
       "13138                    0.006394 -0.000226     -0.000226     -0.000226   \n",
       "13139                    0.007191  0.000146      0.000146      0.000146   \n",
       "\n",
       "         yearly  yearly_lower  yearly_upper  additive_terms  \\\n",
       "0      0.008399      0.008399      0.008399             0.0   \n",
       "1      0.008230      0.008230      0.008230             0.0   \n",
       "2      0.007999      0.007999      0.007999             0.0   \n",
       "3      0.007705      0.007705      0.007705             0.0   \n",
       "4      0.007345      0.007345      0.007345             0.0   \n",
       "...         ...           ...           ...             ...   \n",
       "13135  0.005051      0.005051      0.005051             0.0   \n",
       "13136  0.005621      0.005621      0.005621             0.0   \n",
       "13137  0.006145      0.006145      0.006145             0.0   \n",
       "13138  0.006620      0.006620      0.006620             0.0   \n",
       "13139  0.007045      0.007045      0.007045             0.0   \n",
       "\n",
       "       additive_terms_lower  additive_terms_upper      yhat  \n",
       "0                       0.0                   0.0  0.039292  \n",
       "1                       0.0                   0.0  0.039292  \n",
       "2                       0.0                   0.0  0.039288  \n",
       "3                       0.0                   0.0  0.039282  \n",
       "4                       0.0                   0.0  0.039272  \n",
       "...                     ...                   ...       ...  \n",
       "13135                   0.0                   0.0  0.847990  \n",
       "13136                   0.0                   0.0  0.848456  \n",
       "13137                   0.0                   0.0  0.848882  \n",
       "13138                   0.0                   0.0  0.849267  \n",
       "13139                   0.0                   0.0  0.850000  \n",
       "\n",
       "[13140 rows x 19 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>typical_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>ds</th>\n",
       "      <th>series</th>\n",
       "      <th>y</th>\n",
       "      <th>smp_weekly</th>\n",
       "      <th>smp_yearly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>1289.994965</td>\n",
       "      <td>1301.677521</td>\n",
       "      <td>1274.834961</td>\n",
       "      <td>1278.892456</td>\n",
       "      <td>1286.349976</td>\n",
       "      <td>4.409700e+09</td>\n",
       "      <td>2008-09-01</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.007586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14123</th>\n",
       "      <td>1287.829956</td>\n",
       "      <td>1303.040039</td>\n",
       "      <td>1272.199951</td>\n",
       "      <td>1277.579956</td>\n",
       "      <td>1285.162476</td>\n",
       "      <td>4.783560e+09</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.007881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14124</th>\n",
       "      <td>1276.609985</td>\n",
       "      <td>1280.599976</td>\n",
       "      <td>1265.589966</td>\n",
       "      <td>1274.979980</td>\n",
       "      <td>1274.444977</td>\n",
       "      <td>5.056980e+09</td>\n",
       "      <td>2008-09-03</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.990745</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.008125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14125</th>\n",
       "      <td>1271.800049</td>\n",
       "      <td>1271.800049</td>\n",
       "      <td>1232.829956</td>\n",
       "      <td>1236.829956</td>\n",
       "      <td>1253.315002</td>\n",
       "      <td>5.212500e+09</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.974319</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>1233.209961</td>\n",
       "      <td>1244.939941</td>\n",
       "      <td>1217.229980</td>\n",
       "      <td>1242.310059</td>\n",
       "      <td>1234.422485</td>\n",
       "      <td>5.017080e+09</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.959632</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.008453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14482</th>\n",
       "      <td>1027.810059</td>\n",
       "      <td>1033.329956</td>\n",
       "      <td>1016.200012</td>\n",
       "      <td>1030.979980</td>\n",
       "      <td>1027.080002</td>\n",
       "      <td>5.785880e+09</td>\n",
       "      <td>2009-08-27</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.798445</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14483</th>\n",
       "      <td>1031.619995</td>\n",
       "      <td>1039.469971</td>\n",
       "      <td>1023.130005</td>\n",
       "      <td>1028.930054</td>\n",
       "      <td>1030.787506</td>\n",
       "      <td>5.785780e+09</td>\n",
       "      <td>2009-08-28</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.801327</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.005757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14484</th>\n",
       "      <td>1029.483317</td>\n",
       "      <td>1034.716634</td>\n",
       "      <td>1020.293335</td>\n",
       "      <td>1026.160034</td>\n",
       "      <td>1027.663330</td>\n",
       "      <td>5.525373e+09</td>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.798899</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.006268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14485</th>\n",
       "      <td>1027.346639</td>\n",
       "      <td>1029.963298</td>\n",
       "      <td>1017.456665</td>\n",
       "      <td>1023.390015</td>\n",
       "      <td>1024.539154</td>\n",
       "      <td>5.264967e+09</td>\n",
       "      <td>2009-08-30</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.796470</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.006731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14486</th>\n",
       "      <td>1025.209961</td>\n",
       "      <td>1025.209961</td>\n",
       "      <td>1014.619995</td>\n",
       "      <td>1020.619995</td>\n",
       "      <td>1021.414978</td>\n",
       "      <td>5.004560e+09</td>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.794041</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open         high          low        close  typical_price  \\\n",
       "14122  1289.994965  1301.677521  1274.834961  1278.892456    1286.349976   \n",
       "14123  1287.829956  1303.040039  1272.199951  1277.579956    1285.162476   \n",
       "14124  1276.609985  1280.599976  1265.589966  1274.979980    1274.444977   \n",
       "14125  1271.800049  1271.800049  1232.829956  1236.829956    1253.315002   \n",
       "14126  1233.209961  1244.939941  1217.229980  1242.310059    1234.422485   \n",
       "...            ...          ...          ...          ...            ...   \n",
       "14482  1027.810059  1033.329956  1016.200012  1030.979980    1027.080002   \n",
       "14483  1031.619995  1039.469971  1023.130005  1028.930054    1030.787506   \n",
       "14484  1029.483317  1034.716634  1020.293335  1026.160034    1027.663330   \n",
       "14485  1027.346639  1029.963298  1017.456665  1023.390015    1024.539154   \n",
       "14486  1025.209961  1025.209961  1014.619995  1020.619995    1021.414978   \n",
       "\n",
       "             volume         ds series         y  smp_weekly  smp_yearly  \n",
       "14122  4.409700e+09 2008-09-01  ^GSPC  1.000000   -0.000226    0.007586  \n",
       "14123  4.783560e+09 2008-09-02  ^GSPC  0.999077    0.000146    0.007881  \n",
       "14124  5.056980e+09 2008-09-03  ^GSPC  0.990745    0.000148    0.008125  \n",
       "14125  5.212500e+09 2008-09-04  ^GSPC  0.974319    0.000073    0.008316  \n",
       "14126  5.017080e+09 2008-09-05  ^GSPC  0.959632    0.000042    0.008453  \n",
       "...             ...        ...    ...       ...         ...         ...  \n",
       "14482  5.785880e+09 2009-08-27  ^GSPC  0.798445    0.000073    0.005198  \n",
       "14483  5.785780e+09 2009-08-28  ^GSPC  0.801327    0.000042    0.005757  \n",
       "14484  5.525373e+09 2009-08-29  ^GSPC  0.798899   -0.000047    0.006268  \n",
       "14485  5.264967e+09 2009-08-30  ^GSPC  0.796470   -0.000137    0.006731  \n",
       "14486  5.004560e+09 2009-08-31  ^GSPC  0.794041   -0.000226    0.007143  \n",
       "\n",
       "[365 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>2008-09-01</td>\n",
       "      <td>0.800661</td>\n",
       "      <td>0.733963</td>\n",
       "      <td>0.881158</td>\n",
       "      <td>0.800661</td>\n",
       "      <td>0.800661</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>0.800720</td>\n",
       "      <td>0.732619</td>\n",
       "      <td>0.887985</td>\n",
       "      <td>0.800720</td>\n",
       "      <td>0.800720</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>2008-09-03</td>\n",
       "      <td>0.800779</td>\n",
       "      <td>0.732364</td>\n",
       "      <td>0.882005</td>\n",
       "      <td>0.800779</td>\n",
       "      <td>0.800779</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12413</th>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>0.800839</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.881983</td>\n",
       "      <td>0.800839</td>\n",
       "      <td>0.800839</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12414</th>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>0.800898</td>\n",
       "      <td>0.732648</td>\n",
       "      <td>0.881129</td>\n",
       "      <td>0.800898</td>\n",
       "      <td>0.800898</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12770</th>\n",
       "      <td>2009-08-27</td>\n",
       "      <td>0.822029</td>\n",
       "      <td>0.749795</td>\n",
       "      <td>0.908188</td>\n",
       "      <td>0.822029</td>\n",
       "      <td>0.822029</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12771</th>\n",
       "      <td>2009-08-28</td>\n",
       "      <td>0.822088</td>\n",
       "      <td>0.748083</td>\n",
       "      <td>0.903065</td>\n",
       "      <td>0.822088</td>\n",
       "      <td>0.822088</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12772</th>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>0.822147</td>\n",
       "      <td>0.753710</td>\n",
       "      <td>0.906201</td>\n",
       "      <td>0.822147</td>\n",
       "      <td>0.822147</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.827262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12773</th>\n",
       "      <td>2009-08-30</td>\n",
       "      <td>0.822207</td>\n",
       "      <td>0.757179</td>\n",
       "      <td>0.902080</td>\n",
       "      <td>0.822207</td>\n",
       "      <td>0.822207</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.827628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12774</th>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.749921</td>\n",
       "      <td>0.904045</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.827953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ds     trend  yhat_lower  yhat_upper  trend_lower  trend_upper  \\\n",
       "12410 2008-09-01  0.800661    0.733963    0.881158     0.800661     0.800661   \n",
       "12411 2008-09-02  0.800720    0.732619    0.887985     0.800720     0.800720   \n",
       "12412 2008-09-03  0.800779    0.732364    0.882005     0.800779     0.800779   \n",
       "12413 2008-09-04  0.800839    0.731868    0.881983     0.800839     0.800839   \n",
       "12414 2008-09-05  0.800898    0.732648    0.881129     0.800898     0.800898   \n",
       "...          ...       ...         ...         ...          ...          ...   \n",
       "12770 2009-08-27  0.822029    0.749795    0.908188     0.822029     0.822029   \n",
       "12771 2009-08-28  0.822088    0.748083    0.903065     0.822088     0.822088   \n",
       "12772 2009-08-29  0.822147    0.753710    0.906201     0.822147     0.822147   \n",
       "12773 2009-08-30  0.822207    0.757179    0.902080     0.822207     0.822207   \n",
       "12774 2009-08-31  0.822266    0.749921    0.904045     0.822266     0.822266   \n",
       "\n",
       "       multiplicative_terms  multiplicative_terms_lower  \\\n",
       "12410              0.007359                    0.007359   \n",
       "12411              0.008028                    0.008028   \n",
       "12412              0.008273                    0.008273   \n",
       "12413              0.008389                    0.008389   \n",
       "12414              0.008496                    0.008496   \n",
       "...                     ...                         ...   \n",
       "12770              0.005271                    0.005271   \n",
       "12771              0.005799                    0.005799   \n",
       "12772              0.006221                    0.006221   \n",
       "12773              0.006594                    0.006594   \n",
       "12774              0.006917                    0.006917   \n",
       "\n",
       "       multiplicative_terms_upper    weekly  weekly_lower  weekly_upper  \\\n",
       "12410                    0.007359 -0.000226     -0.000226     -0.000226   \n",
       "12411                    0.008028  0.000146      0.000146      0.000146   \n",
       "12412                    0.008273  0.000148      0.000148      0.000148   \n",
       "12413                    0.008389  0.000073      0.000073      0.000073   \n",
       "12414                    0.008496  0.000042      0.000042      0.000042   \n",
       "...                           ...       ...           ...           ...   \n",
       "12770                    0.005271  0.000073      0.000073      0.000073   \n",
       "12771                    0.005799  0.000042      0.000042      0.000042   \n",
       "12772                    0.006221 -0.000047     -0.000047     -0.000047   \n",
       "12773                    0.006594 -0.000137     -0.000137     -0.000137   \n",
       "12774                    0.006917 -0.000226     -0.000226     -0.000226   \n",
       "\n",
       "         yearly  yearly_lower  yearly_upper  additive_terms  \\\n",
       "12410  0.007586      0.007586      0.007586             0.0   \n",
       "12411  0.007881      0.007881      0.007881             0.0   \n",
       "12412  0.008125      0.008125      0.008125             0.0   \n",
       "12413  0.008316      0.008316      0.008316             0.0   \n",
       "12414  0.008453      0.008453      0.008453             0.0   \n",
       "...         ...           ...           ...             ...   \n",
       "12770  0.005198      0.005198      0.005198             0.0   \n",
       "12771  0.005757      0.005757      0.005757             0.0   \n",
       "12772  0.006268      0.006268      0.006268             0.0   \n",
       "12773  0.006731      0.006731      0.006731             0.0   \n",
       "12774  0.007143      0.007143      0.007143             0.0   \n",
       "\n",
       "       additive_terms_lower  additive_terms_upper      yhat  \n",
       "12410                   0.0                   0.0  0.806553  \n",
       "12411                   0.0                   0.0  0.807148  \n",
       "12412                   0.0                   0.0  0.807404  \n",
       "12413                   0.0                   0.0  0.807557  \n",
       "12414                   0.0                   0.0  0.807702  \n",
       "...                     ...                   ...       ...  \n",
       "12770                   0.0                   0.0  0.826361  \n",
       "12771                   0.0                   0.0  0.826855  \n",
       "12772                   0.0                   0.0  0.827262  \n",
       "12773                   0.0                   0.0  0.827628  \n",
       "12774                   0.0                   0.0  0.827953  \n",
       "\n",
       "[365 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_yhat[\n",
    "    (context_yhat[\"ds\"] >= proba[\"ds\"].iloc[0])\n",
    "    & (context_yhat[\"ds\"] <= proba[\"ds\"].iloc[-1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "412it [01:45,  3.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3071037943690201"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_forecasts = []\n",
    "\n",
    "for df, df_test in tqdm(zip(train_df_ticker, test_df_tickers)):\n",
    "    prophet = Prophet(seasonality_mode=\"additive\")\n",
    "    prophet.add_regressor(\"smp_weekly\", standardize=False, mode=\"additive\")\n",
    "    prophet.add_regressor(\"smp_yearly\", standardize=False, mode=\"additive\")\n",
    "    prophet.add_regressor(\"smp_yhat\", standardize=False, mode=\"additive\")\n",
    "\n",
    "    train_df = df.copy()\n",
    "    train_df[\"smp_weekly\"] = context_yhat[\n",
    "        (context_yhat[\"ds\"] >= train_df[\"ds\"].iloc[0])\n",
    "        & (context_yhat[\"ds\"] <= train_df[\"ds\"].iloc[-1])\n",
    "    ][\"weekly\"].to_numpy()\n",
    "    train_df[\"smp_yhat\"] = context_yhat[\n",
    "        (context_yhat[\"ds\"] >= train_df[\"ds\"].iloc[0])\n",
    "        & (context_yhat[\"ds\"] <= train_df[\"ds\"].iloc[-1])\n",
    "    ][\"yhat\"].to_numpy()\n",
    "    train_df[\"smp_yearly\"] = context_yhat[\n",
    "        (context_yhat[\"ds\"] >= train_df[\"ds\"].iloc[0])\n",
    "        & (context_yhat[\"ds\"] <= train_df[\"ds\"].iloc[-1])\n",
    "    ][\"yearly\"].to_numpy()\n",
    "\n",
    "    prophet.fit(train_df)\n",
    "\n",
    "    future = prophet.make_future_dataframe(periods=365, include_history=True)\n",
    "    future[\"smp_weekly\"] = context_yhat[\n",
    "        (context_yhat[\"ds\"] >= future[\"ds\"].iloc[0])\n",
    "        & (context_yhat[\"ds\"] <= future[\"ds\"].iloc[-1])\n",
    "    ][\"weekly\"].to_numpy()\n",
    "    future[\"smp_yhat\"] = context_yhat[\n",
    "        (context_yhat[\"ds\"] >= future[\"ds\"].iloc[0])\n",
    "        & (context_yhat[\"ds\"] <= future[\"ds\"].iloc[-1])\n",
    "    ][\"yhat\"].to_numpy()\n",
    "    future[\"smp_yearly\"] = context_yhat[\n",
    "        (context_yhat[\"ds\"] >= future[\"ds\"].iloc[0])\n",
    "        & (context_yhat[\"ds\"] <= future[\"ds\"].iloc[-1])\n",
    "    ][\"yearly\"].to_numpy()\n",
    "\n",
    "    prophet_forecasts.append(prophet.predict(future))\n",
    "\n",
    "prophet_metrics = get_prophet_metrics(test_df_tickers, prophet_forecasts, 365)\n",
    "prophet_metrics[\"mape\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23612748762805383"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_metrics[\"mape\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
